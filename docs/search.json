[{"path":"https://bafg-bund.github.io/ntsportal/articles/Add-measurement-file-to-msrawfiles.html","id":"checking-coherency-of-msrawfiles-after-completion","dir":"Articles","previous_headings":"","what":"Checking coherency of msrawfiles after completion","title":"Adding measurement files to msrawfiles","text":"uploads complete, check msrawfiles errors. step takes minutes, recommended files loaded.","code":"ntsportal::checkMsrawfiles()"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Add-measurement-file-to-msrawfiles.html","id":"function-description","dir":"Articles","previous_headings":"","what":"Function description","title":"Adding measurement files to msrawfiles","text":"function designed make adding new files msrawfiles quick error-free possible.","code":""},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/articles/Add-measurement-file-to-msrawfiles.html","id":"the-files-being-added-have-different-measurement-locations","dir":"Articles","previous_headings":"Special cases","what":"The files being added have different measurement locations","title":"Adding measurement files to msrawfiles","text":"location must coded filename. field dbas_station_regex template document used find correct station existing entries msrawfiles. Use newStation = \"filename\" copy location information entries Example filename: OBF34910_20230821_Zschopau_pos.mzXML Example dbas_station_regex: ^(OBF\\\\d{5})_","code":"addRawfiles(rfindex, \"eIRBnYkBcjCrX8D7v4H5\", newFiles[4:17], newStation = \"filename\",               dirMeasurmentFiles = \"~/messdaten/sachsen/\")"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"aggregation-terms","dir":"Articles","previous_headings":"","what":"Aggregation: terms","title":"Aggregations with ElasticSearch Query DSL","text":"terms aggregation groups documents returned query buckets according keyword boolean field. code search two stations split results station, polarity blank yes/via three nested terms aggregations. Note: terms query terms aggregation two different things. first filters results multiple possible values (keyword field), second splits filtered results (documents) buckets based keyword field. example three terms aggregations nested , say, station bucket split polarity buckets split field blank (boolean).","code":"GET ntsp_msrawfiles/_search {   \"query\": {     \"terms\": {                 // terms query       \"station\": [         \"donau_ul_m\",         \"saale_wettin_m\"       ]     }   },    \"size\": 0,                   // Don't return any documents (just show aggregations)   \"aggs\": {     \"messstellen\": {           // just a variable name you give it (can be anything)       \"terms\": {               // terms aggregation         \"field\": \"station\"       },       \"aggs\": {         \"polaritaet\": {           \"terms\": {           // terms aggregation             \"field\": \"pol\"           },           \"aggs\": {             \"methoden_blanks\": {               \"terms\": {       // terms aggregation                 \"field\": \"blank\"               }             }           }         }       }     }   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"overview-of-all-compounds","dir":"Articles","previous_headings":"Aggregation: terms","what":"Overview of all compounds","title":"Aggregations with ElasticSearch Query DSL","text":"aggregation also show polarities matrices compound found. Explanations:ntsp_dbas* – index pattern, indices starting character string selected.\"size\": 1000 – maximum number buckets create. default 10.","code":"GET ntsp_dbas*/_search?size=0   // Size is 0, meaning no docs are returned (only aggregations) {                             // Since there is no query, all docs are used for the aggregations   \"aggs\": {     \"comps\": {       \"terms\": {         \"field\": \"name\",         \"size\": 1000           // Default is 10, set higher until “sum_other_doc_count” (see response) is -0-       },       \"aggs\": {         \"pols\": {           \"terms\": {             \"field\": \"pol\"     // There are only 2 polarities, no need to set the size           },           \"aggs\": {             \"matrix\": {               \"terms\": {                 \"field\": \"matrix\"               }             }           }         }       }     }   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"bucket-aggregations-and-metric-aggregations","dir":"Articles","previous_headings":"","what":"Bucket aggregations and metric aggregations","title":"Aggregations with ElasticSearch Query DSL","text":"Refer extensive documentation elastic.com. example, term query used filter data suspended particulate matter (spm). detections binned station name (terms bucket aggregation) station latest file upload time returned (max metric aggregation).","code":"GET ntsp_msrawfiles/_search {   \"query\": {     \"term\": {       \"matrix\": {         \"value\": \"spm\"       }     }   },   \"size\": 0,   \"aggs\": {     \"messstellen\": {       \"terms\": {         \"field\": \"station\"       },       \"aggs\": {         \"neuste\": {           \"max\": {             \"field\": \"date_import\"           }         }       }     }   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"combining-aggregations-and-a-bool-query","dir":"Articles","previous_headings":"Bucket aggregations and metric aggregations","what":"Combining aggregations and a bool query","title":"Aggregations with ElasticSearch Query DSL","text":"query : station: ulm wettin, blank: blank documents split station polarity","code":"GET ntsp_msrawfiles/_search {   \"query\": {     \"bool\": {       \"must\": [         {           \"terms\": {             \"station\": [               \"donau_ul_m\",               \"saale_wettin_m\"             ]           }         },         {           \"term\": {             \"blank\": {               \"value\": \"false\"             }           }         }       ]     }   },   \"aggs\": {     \"kontrolle\": {       \"terms\": {         \"field\": \"station\"       },       \"aggs\": {         \"polaritaet\": {           \"terms\": {             \"field\": \"pol\"           }         }       }     }   }, \"size\": 0 }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"aggregation-geotile_grid","dir":"Articles","previous_headings":"","what":"Aggregation: geotile_grid","title":"Aggregations with ElasticSearch Query DSL","text":"Return documents matching pattern split results coordinates (geopoint) precision can set maximum value since within station coordinates must exactly .","code":"GET ntsp_msrawfiles/_search {   \"query\": {     \"regexp\": {       \"station\": \".*NA\"     }   },   \"size\": 0,   \"aggs\": {     \"stations\": {       \"terms\": {         \"field\": \"station\"       },       \"aggs\": {         \"locations\": {           \"geotile_grid\": {             \"field\": \"loc\",             \"precision\": 21,             \"size\": 10           }         }       }     }   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"aggregation-cardinality","dir":"Articles","previous_headings":"","what":"Aggregation: cardinality","title":"Aggregations with ElasticSearch Query DSL","text":"cardinality aggregation counts number unique entries keyword field. example want know many different compounds found database. example two aggregations set parallel (nested).","code":"GET ntsp_dbas_upb/_search             // Index to search {   \"query\": {     \"match_all\": {}                 // Match all docs   },   \"size\": 0,                        // don't return any docs   \"aggs\": {                         // There are two different aggregations listed here     \"num_different_comps\": {        // Aggregation 1 determines the number of different compounds       \"cardinality\": {             \"field\": \"name\",         \"precision_threshold\": 1000 // default is 100, need to set it higher because we have ca. 400       }     },     \"comps_buckets\": {              // Aggregation 2 splits docs into buckets by compound name       \"terms\": {                             \"field\": \"name\",         \"size\": 1000                // default is 10, set higher until “sum_other_doc_count” is -0- (see response)       }     }   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"filtering-buckets-by-their-doc-counts","dir":"Articles","previous_headings":"","what":"Filtering buckets by their doc counts","title":"Aggregations with ElasticSearch Query DSL","text":"example buckets filtered compounds found 10 times total days compound found returned.","code":"GET ntsp_dbas_v231006_frame/_search?size=0 {   \"query\": {     \"term\": {       \"pol\": {         \"value\": \"pos\"       }     }   },   \"aggs\": {     \"comps\": {       \"terms\": {         \"field\": \"name\",         \"size\": 1000       },       \"aggs\": {         \"comps_selector\": {           \"bucket_selector\": {             \"buckets_path\": {               \"numSamplesPerComp\": \"_count\"             },             \"script\": \"params.numSamplesPerComp >= 10\"           }         },         \"samples\": {           \"date_histogram\": {             \"field\": \"start\",             \"calendar_interval\": \"1d\"           },           \"aggs\": {             \"days_selector\": {               \"bucket_selector\": {                 \"buckets_path\": {                   \"numSamplesPerDay\" : \"_count\"                 },                 \"script\": \"params.numSamplesPerDay > 0\"               }             }           }         }       }     },     \"files\": {       \"cardinality\": {         \"field\": \"filename\"       }     }   } }"},{"path":[]},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/articles/Dashboard-development.html","id":"structural-formula-visualization","dir":"Articles","previous_headings":"Spectral library dashboard","what":"Structural formula visualization","title":"Dashboard development and backend","text":"VEGA graphic retrieves image based first inchikey provided Kibana search context. Structures rendered asynchronously. structures saved PNG files sychronized image server picture.ntsportal.bafg.de. process must started NTSPortal administrator new CSL version used NTSPortal. function createAllStructures creates structural formulas compounds CSL. consists 5 steps: Optional: avoid accidental manipulation CSL database, copy created working directory. compound list extracted SQlite .db file help RSQlite package. SMILES code compound converted structural formula rcdk package (requires rJava). formulas exported .png files folder synchronized picture server, can accessed Kibana. file names InChiKeys substances. Optional: copy CSL removed working directory.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"zugang","dir":"Articles","previous_headings":"","what":"Zugang","title":"Kurzanleitung zur ersten Nutzung","text":"Das NTS-Portal ist unter folgendem Link erreichbar: ntsportal.bafg.de Username und Passwort für neue Nutzer können per E-Mail beantragt werden: ntsportal mailbox","code":""},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"startseite","dir":"Articles","previous_headings":"Überblick und erste Möglichkeiten","what":"Startseite","title":"Kurzanleitung zur ersten Nutzung","text":"Der Link führt zur Startseite der Datenbank für annotierte Substanzen. Links finden sich Quicklinks zu verschiedenen Bereichen, der Mitte ein Überblick über die erfassten Daten und rechts eine Karte aller Messstationen für Wasser- (blau) und SPM-Proben (braun).","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"tasks-search-for-substances","dir":"Articles","previous_headings":"Überblick und erste Möglichkeiten","what":"Tasks: Search for substances","title":"Kurzanleitung zur ersten Nutzung","text":"Über den Quicklink „Search substances” gelangt man zu einer Übersicht aller annotierten Substanzen allen Messstellen. Über die Dropdown Menüs unterhalb des Suchfelds kann man nach bestimmten Substanzen („Comp. name”), Summenformeln, CAS-Nummern oder auch Massenbereichen filtern. Es lassen sich auch mehrere Einträge den Dropdown Menüs anklicken, dass man z.B. mehrere Substanzen (hier: Benzotriazole, Candesartan und Sitagliptin) gleichzeitig betrachten kann. Die Karte passt sich der gefilterten Tabelle . Klickt man mit der Maus der Karte auf eine bestimmte Messstelle, erhält man einen Überblick über die Metadaten der Messstelle und kann über das Symbol recht der Zeile „station” einen Filter für diese Messstelle setzen. Die Angaben der Tabelle beziehen dann nur noch auf die dieser Messstelle erhobenen Daten. Fährt man mit der Maus über den Substanznamen der Tabelle, zeigt sich ein Auswahlmenü. Klickt man auf das „+“-Zeichen, kann man den Substanzfilter direkt einen anderen Quicklink der Gruppe „Analytical Data” übertragen, z. B. „Time series water”. Es öffnet sich ein neuer Tab.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"analytical-data-time-series-water","dir":"Articles","previous_headings":"Überblick und erste Möglichkeiten","what":"Analytical Data: Time series water","title":"Kurzanleitung zur ersten Nutzung","text":"Unter “Time series water samples” sind nur die Messstationen hinterlegt, für die zeitlich aufgelöste Proben vorliegen (Rhein und Elbe). Geht man direkt über die Startseite hierhin, kann man über das Dropdown Menü Filterungen vornehmen. Hat man bereits, wie 2.2 beschrieben, Filterungen vorgenommen, werden hier direkt die entsprechenden Zeitreihen angezeigt. Auch hier kann man mit einem Klick auf die Messstelle der Karte oder durch die Auswahl im Dropdown Menü “Station” die angezeigten Daten auf eine Messstelle eingrenzen. Im Beispiel waren drei Substanzen ausgewählt. Für diese werden den Diagrammen die Zeitreihen einmal normiert auf einen (oben) und nicht normiert (unten) dargestellt. Ist eine Substanz sowohl im positiven als auch im negativen Modus ionisierbar und messbar, werden beide Datensätze angezeigt. Fährt man mit dem Mauszeigen den Legenden der Zeitreihen die einzelnen Datenreihen ab, werden alle anderen ausgegraut. Mit Klick auf eine Datenreihe, wird nur noch diese angezeigt (kann durch einen weiteren Klick rückgängig gemacht werden).","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"analytical-data-time-series-spm","dir":"Articles","previous_headings":"Überblick und erste Möglichkeiten","what":"Analytical Data: Time series SPM","title":"Kurzanleitung zur ersten Nutzung","text":"Dieser Bereich ist ähnlich aufgebaut wie „Time series water” und kann auf die gleiche Weise verwendet werden.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Library screening","text":"Measurement files processed using library screening algorithm known DBAS. parameters processing, well location necessary input files, stored msrawfiles index. output stored dbas index. See naming conventions indices.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"reprocessing-all-datafiles-in-msrawfiles-index","dir":"Articles","previous_headings":"","what":"Reprocessing all datafiles in msrawfiles index","title":"Library screening","text":"additions made spectral library datafiles must reprocessed. making necessary changes msrawfiles table, processing can started various dbaScreening* functions depending processing take place (locally, server etc.). example, dbaScreeningSelectedBatchesSlurm used begin processing using SLURM workload manager.","code":""},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"connecting-to-elasticsearch-cluster","dir":"Articles","previous_headings":"Overview of processing algorithm","what":"Connecting to ElasticSearch cluster","title":"Library screening","text":"Connection within BfG achieved R using connectNtsp() function. use stored credentials (stored keyring file back-end) build connection (connection details used create escon interface use R-package elastic used build PythonDbComm interface).","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"general-workflow","dir":"Articles","previous_headings":"Overview of processing algorithm","what":"General workflow","title":"Library screening","text":"HRMS measurement files stored filesystem directories representing batches (measurement sequences). msrawfiles index used manage metadata. file record contains information file location, sampling information processing parameters. msrawfile-records used control processing workflow. workflow complete, data saved json file format needed Elasticsearch ingest. ingest done separate step.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"process-launching","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Process launching","title":"Library screening","text":"user runs function start screening either locally via SLURM. function batches process either selected passing specific directories either listing directly giving root directory. Alternatively user can process “new” batches","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"processing-using-the-workflow-manager-slurm","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow > Process launching","what":"Processing using the workflow manager SLURM","title":"Library screening","text":"run screening via SLURM, first necessary job files generated. user must start actual processing submitting job file (.sbatch) workload manager.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"sec-collectingMsrawfileRecords","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Collecting msrawfile-records","title":"Library screening","text":"New batches selected based looking feature indices comparing msrawfiles. batches msrawfiles yet found feature index (based presence directory path field) processed. msrawfile records loaded checks performed scanning process begins. Output list batches ntsportal::msrawfileRecords. See @sec-batchSelection.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"file-wise-scanning","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"File-wise scanning","title":"Library screening","text":"measurement files scanned cleaned using different algorithms. Currently “dbas” development. result one ntsportal::dbasResult object batch (list containing peak tables whole batch).","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"conversion-to-ntsportal-feature-format","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Conversion to ntsportal “feature” format","title":"Library screening","text":"results scanning cleaning converted list format ntsportal. Output list ntsportal::featureRecords. essentially involves converting feature table list record objects. Compound sample information (measurement file metadata) added record, well MS1, MS2 spectra EIC peak.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"writing-json-for-database-import-ingest","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Writing json for database import (ingest)","title":"Library screening","text":"list featureRecord objects saved json file compressed gzip (json.gz file).","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Library-screening.html","id":"database-import-ingest","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Database import (ingest)","title":"Library screening","text":"json files ingested via ingestJson calls python functions. user must run function separately processing complete.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Measurement-file-naming-conventions.html","id":"bfg-measurement-file-naming","dir":"Articles","previous_headings":"","what":"BfG measurement file naming","title":"Measurement file naming conventions","text":"Filenames always use lowercase letters (-z) Windows ignores capitalization Linux . Replicates named extrepX injrepX extraction injection replicates, respectively. X number 1-9. Parameters insert indicated <> text fixed must copied exactly. Optional parameters given additionally square brackets []","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Measurement-file-naming-conventions.html","id":"general-parameter-descriptions","dir":"Articles","previous_headings":"BfG measurement file naming","what":"General parameter descriptions","title":"Measurement file naming conventions","text":"<pol>: polarity (“pos” “neg”) <station>: see station naming conventions <composite type>: Jahresmischprobe “jmp”, Monatsmischprobe “mmp”, Tagesmischprobe “tmp”, Stichprobe “sp”","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Measurement-file-naming-conventions.html","id":"frame-reference-samples","dir":"Articles","previous_headings":"BfG measurement file naming","what":"FRAME reference samples","title":"Measurement file naming conventions","text":"<Messdatum YYYY-MM-DD>_frame_mix_<instrument>_<concentration>ngl[_injrep<X>]_<pol> <instrument>: “wasser_tof” “sediment_tof”<concentration>: concentration ng/L<X>: replicate number (1-9) (one digit) Example: 2024-02-29_frame_mix_wasser_tof_1000ngl_injrep3_pos.wiff","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Measurement-file-naming-conventions.html","id":"ase-blanks","dir":"Articles","previous_headings":"BfG measurement file naming","what":"ASE blanks","title":"Measurement file naming conventions","text":"<Messdatum YYYY-MM-DD>_ase_bw_<XX>_e<Extraktionsdatum YYYY-MM-DD>_<pol> <XX>: Continuous numbering within job (e.g. one year composite samples stations) (01-99, 2 digits) Example:2024-08-30_ase_bw_01_e2024-07-01_pos.wiff","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Measurement-file-naming-conventions.html","id":"ase-reference-samples","dir":"Articles","previous_headings":"BfG measurement file naming","what":"ASE reference samples","title":"Measurement file naming conventions","text":"<Messdatum YYYY-MM-DD>_ase_ref_<XXX>_e<Extraktionsdatum YYYY-MM-DD>_<pol> <XXX>: Continuous numbering… forever (001-999, three digits) Example:2024-08-30_ase_ref_001_e2024-07-01_pos.wiff","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Measurement-file-naming-conventions.html","id":"monthly-and-yearly-composite-spm-samples-umweltprobenbank","dir":"Articles","previous_headings":"BfG measurement file naming","what":"Monthly and yearly composite SPM samples (umweltprobenbank)","title":"Measurement file naming conventions","text":"<station>_<Probenamedatum YYYY / YYYY-MM>_<composite type>_extrep<X>_<pol> <X>: replicate number (1-9, one digit) Example:rhein_ko_l_2023_jmp_extrep1_pos.wiff","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Measurement-file-naming-conventions.html","id":"daily-composite-samples-water-matrix-bfg-stations","dir":"Articles","previous_headings":"BfG measurement file naming","what":"Daily composite samples water matrix (BfG stations)","title":"Measurement file naming conventions","text":"<station>_<Probenamedatum YYYY-MM-DD>_<composite type>[_injrep<X>]_<pol> <X>: replicate number (1-9) (one digit) Example:rhein_ko_l_2025-01-13_tmp_pos.wiff","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Measurement-file-naming-conventions.html","id":"old-naming","dir":"Articles","previous_headings":"BfG measurement file naming","what":"Old naming","title":"Measurement file naming conventions","text":"Old station naming monatsmischproben Old naming system annual composite samples: ‘JJ’ refers two digit year, ‘X’ replicate number.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Modify-documents-using-API.html","id":"overwrite-a-value","dir":"Articles","previous_headings":"","what":"Overwrite a value","title":"Modifying documents using the Update By Query API","text":"IMPORTANT: Always run query first using GET <INDEX>/_search check results correct. copy query POST statement. careful copying code previous command change necessary values. Use update query API. Example:","code":"GET <INDEX>/_search {   \"query\": {     \"term\": {       \"station\": \"NAME1\"     }   } }  POST <INDEX>/_update_by_query {   \"query\": {     \"term\": {       \"station\": \"NAME1\"     }   },   \"script\" : \"ctx._source.station = 'NAME2'\" }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Modify-documents-using-API.html","id":"overwrite-a-field-via-a-painless-script","dir":"Articles","previous_headings":"Overwrite a value","what":"Overwrite a field via a Painless script","title":"Modifying documents using the Update By Query API","text":"case want change station name adding prefix part existing station name. Note: third debug statement active code . + used string concatination. declare string must use String. split string character use string method splitOnToken. produces array.","code":"GET <INDEX>/_search {   \"query\" : {     \"regexp\": {       \"station\": \"ow_.*\"     }   },   \"aggs\": {     \"stations\": {       \"terms\": {         \"field\": \"station\",         \"size\": 11       }     }   },   \"size\": 0 }  POST <INDEX>/_update_by_query {   \"query\" : {     \"regexp\": {       \"station\": \"OW_\\\\d+\"     }   },   \"script\": {     \"source\": \"\"\"       // Debug.explain(params.new_prefix);       // Debug.explain(params.newPrefix + ctx._source.station.splitOnToken('_')[1]);       String newName = params.newPrefix + ctx._source.station.splitOnToken('_')[1];       Debug.explain(newName)       ctx._source.station = newName;       \"\"\",     \"params\": {       \"newPrefix\": \"ow_hess_ried_\"     }   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Modify-documents-using-API.html","id":"create-or-append-to-array","dir":"Articles","previous_headings":"","what":"Create or append to array","title":"Modifying documents using the Update By Query API","text":"entry treated array (multiple entries), tag comment fields, need explicitly saved arrays. following script test entry exists create array. already entry (array ) make array append new value. field values change given params field script.","code":"POST <INDEX>/_update_by_query {   \"query\": {     <query code>   },   \"script\": {     \"params\": {       \"fieldToChange\": \"comment\",       \"newValue\": \"Instrument name: Sediment TOF\"     },     \"source\": \"\"\"       if (ctx._source[params.fieldToChange] == null) {         ctx._source[params.fieldToChange] = [params.newValue];       } else if (!(ctx._source[params.fieldToChange] instanceof List)) {         ctx._source[params.fieldToChange] = [ctx._source[params.fieldToChange]];         ctx._source[params.fieldToChange].add(params.newValue);       } else {         ctx._source[params.fieldToChange].add(params.newValue)       }       \"\"\"   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"simple-search-example-with-the-term-query","dir":"Articles","previous_headings":"","what":"Simple search example with the term query","title":"Station naming conventions","text":"retrieve detections station “mosel_ko_r” run following dev console:","code":"GET ntsp_dbas*/_search {   \"query\": {     \"term\": {       \"station\": \"mosel_ko_r\"     }   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"combining-search-parameters-with-bool","dir":"Articles","previous_headings":"","what":"Combining search parameters with bool","title":"Station naming conventions","text":"example search datafiles : polarity negative, blanks, stations ulm wettin.","code":"GET ntsp_msrawfiles/_search {   \"query\": {     \"bool\": {       \"must\": [         {           \"term\": {             \"pol\": {               \"value\": \"neg\"             }           }         }       ],       \"must_not\": [         {           \"term\": {             \"blank\": {               \"value\": \"true\"             }           }         }       ],       \"should\": [         {           \"term\": {             \"station\": {               \"value\": \"donau_ul_m\"             }           }         },         {           \"term\": {             \"station\": {               \"value\": \"saale_wettin_m\"             }           }         }       ],        \"minimum_should_match\": 1     }   } }"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Station-naming.html","id":"general-conventions","dir":"Articles","previous_headings":"","what":"General conventions","title":"Station naming conventions","text":"stations named best possible convention <river>_<location>_<bank>. river name uses local spelling complete character set (ß etc.). enables easier wildcard searching, example rhein* find measurement stations Rhine river. location can either town, district, river-km (must km , e.g., donau_km50, . used decimals). Numbering stations along river accepted (either numbers letters, e.g., permitted: elbe_1, lahn_a. code used location, e.g. jo Jochenstein, code needs added table . bank indicates bank sample taken (left: l, right: r, m middle). Banks always named direction flow, canals see Teil II Binnenschiffahrtsverordnung. text lower-case without spaces, punctuation special characters (´, \", ,, etc.).","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Station-naming.html","id":"table-of-station-codes","dir":"Articles","previous_headings":"","what":"Table of station codes","title":"Station naming conventions","text":"See also Gist Station descriptions: Schulze, T.; Ricking, M. (2005): Abschlussbericht: Entwicklung einer Verfahrensrichtlinie „Sedimente und Schwebstoffe“. Freie Universität Berlin, Umweltbundesamt, UBA, Berlin. Link","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Structure-of-NTSPortal.html","id":"index-mappings-db-schema","dir":"Articles","previous_headings":"","what":"Index mappings (DB Schema)","title":"Structure of NTSPortal","text":"ElasticSearch uses indices store data. NTSPortal contains different index types, different structure. mapping code field descriptions different tables: dbas (results library screening data processing) msrawfiles (metadata processing parameters measurement files) analysis_dbas (summary statistics dbas) spectral_library (copy collective spectral library - CSL)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Structure-of-NTSPortal.html","id":"index-naming-conventions","dir":"Articles","previous_headings":"","what":"Index naming conventions","title":"Structure of NTSPortal","text":"indices named using convention:ntsp<version number>_index_<optional specification, e.g. 'analysis'>_<index type, e.g. 'dbas'>_v<ingest time  'YYMMDDHHmmSS'>_<project institute, e.g. 'bfg'> example: ntsp25.1_index_analysis_dbas_v240215101520_bfg, ntsp25.1_index_nts_v240316101520_lanuv defined codes project institute. exception msrawfiles index, since one alias, just called ntsp25.1_msrawfiles. index type can number indices, particular project, institute subset data.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Structure-of-NTSPortal.html","id":"aliases","dir":"Articles","previous_headings":"","what":"Aliases","title":"Structure of NTSPortal","text":"ElasticSearch uses aliases make accessing index easier. names designed shorter change. point index. aliases following naming convention:ntsp<version number>_<optional specification, e.g. 'analysis'>_<index type, e.g. 'dbas'>_<project institute, e.g. 'bfg'> example: ntsp25.1_dbas_bfg alias point current version index. way, several versions index can maintained concurrently testing backup purposes.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Structure-of-NTSPortal.html","id":"data-views","dir":"Articles","previous_headings":"","what":"Data views","title":"Structure of NTSPortal","text":"Kibana uses data views allow granular data access rights. data view name pattern potentially matching one several indices (aliases). user role, role given access specific indices. dashboards Kibana built data views programmed users role determines indices visible dashboard. example data view : ntsp25.1_dbas*. data view access aliases ntsp25.1_dbas_bfg ntsp25.1_dbas_lanuv, example. user role ntsp_lanuv, access aliases therefore linked indices, see datasets viewing dashboard visual using data view. important alias names subset indices. ntsp_is_dbas alias correct ntsp_dbas_is incorrect. second alias also match data view ntsp_dbas* therefore internal standard data appear together results. following table shows examples naming conventions","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Using-API-in-R.html","id":"api-connection-getting-started","dir":"Articles","previous_headings":"","what":"API Connection, getting started","title":"Using the NTSPortal Elasticsearch Search API in R","text":"API called elastic.bafg.de. Users must 1) granted API access (please send request ntsportal@bafg.de) 2) must created API key ntsportal.bafg.de (Menu->Management->Stack Management->Security->API keys) API documentation found . Detailed documentation available different search languages offered, e.g. Query DSL ES|QL.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/Using-API-in-R.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the NTSPortal Elasticsearch Search API in R","text":"R-package elastic allows calls ElasticSearch API within R json data returned list data.frame. list can reformatted data.frame analysis R. best way get started test query kibana dev tools console copy query, text, R run command . Since elastic longer maintained, preferred option use Python elasticsearch elasticsearch-dsl modules within R using reticulate. PythonDbComm class uses .","code":""},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/articles/Using-API-in-R.html","id":"example-using-a-config-yml","dir":"Articles","previous_headings":"Connect using R","what":"Example using a config.yml","title":"Using the NTSPortal Elasticsearch Search API in R","text":"Depending security settings, username password may sufficient connect elasticsearch API. Alternatively, API Key may needed. config.yml holds username password form: code can saved script e.g. connect-ntsp.R run R-script source(\"~/connect-ntsp.R\") thereby producing elastic::connect variable escon","code":"default:   elastic_connect:     user: 'XXXXXXXX'     pwd:  'XXXXXXXX' config_path <- \"~/config.yml\"  ec <- config::get(\"elastic_connect\", file = config_path)  escon <- elastic::connect(   host = 'xxxxx.bafg.de',    port = XXX, user=ec$user,    pwd  = ec$pwd,   transport_schema = \"https\" )  if (escon$ping()$cluster_name != \"bfg-elastic-cluster\") {   stop(\"Connection to es-db not established\") }  rm(config_path) rm(ec)  logger::log_info(\"Connection to ntsp successful\")"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Using-API-in-R.html","id":"ignoring-ssl-verification","dir":"Articles","previous_headings":"Connect using R","what":"Ignoring SSL verification","title":"Using the NTSPortal Elasticsearch Search API in R","text":"certificate error, can turn SSL verification:","code":"escon <- elastic::connect(   host = 'xxxx.bafg.de',    port = XXX, user=ec$user,    pwd  = ec$pwd,   transport_schema = \"https\",   ssl_verifypeer = F )"},{"path":"https://bafg-bund.github.io/ntsportal/articles/Using-API-in-R.html","id":"check-your-ip","dir":"Articles","previous_headings":"Connect using R","what":"Check your IP","title":"Using the NTSPortal Elasticsearch Search API in R","text":"check IP trying connect:","code":"library(rjson) fromJSON(readLines(\"http://api.hostip.info/get_json.php\", warn=F))$ip"},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/articles/Using-API-in-R.html","id":"getting-a-data-frame-with-chosen-fields-for-a-simple-query","dir":"Articles","previous_headings":"Examples","what":"Getting a data.frame with chosen fields for a simple query","title":"Using the NTSPortal Elasticsearch Search API in R","text":"example, retrieving documents measurement station “mosel_ko_r” (Moselle, Koblenz, right bank). Using dev tools console, make following request: Response: response shows total number hits greater equal (gte) 10000 (max documents reached). Therefore, can retrieve documents one request must paginate search results. function ntsportal::esSearchPaged works similarly elastic::Search paginate results.","code":"GET ntsp_dbas*/_search {   \"query\": {     \"term\": {       \"station\": {         \"value\": \"mosel_ko_r\"       }     }   },   \"_source\": [\"name\", \"inchikey\", \"pol\", \"start\", \"duration\",                \"area\", \"area_is\", \"area_normalized\"] } {   \"took\": 15,   \"timed_out\": false,   \"_shards\": {     \"total\": 15,     \"successful\": 15,     \"skipped\": 0,     \"failed\": 0   },   \"hits\": {     \"total\": {       \"value\": 10000,       \"relation\": \"gte\"     },     \"max_score\": 0.71082175,     \"hits\": [       {         \"_index\": \"g2_dbas_v231229_expn\",         \"_id\": \"6krzxIwB6C8k9zJxN0cV\",         \"_score\": 0.71082175,         \"_source\": {           \"name\": \"Oleamide\",           \"area\": 50,           \"area_is\": 1770,           \"area_normalized\": 0.0283,           \"start\": \"2021-05-26\",           \"duration\": 1,           \"pol\": \"pos\"         }       },       {         \"_index\": \"g2_dbas_v231229_expn\",       ... connectNtsportal() res <- esSearchPaged(\"ntsp25.1_dbas*\", searchBody = list(query = list(term = list(station = \"mosel_ko_r\"))),     source = c(\"name\", \"inchikey\", \"pol\", \"start\", \"duration\", \"area\"), sort = \"mz\")   # Convert the returned list to a data.frame temp <- lapply(res$hits$hits, function(x) as.data.frame(x[[\"_source\"]])) df <- plyr::rbind.fill(temp)"},{"path":"https://bafg-bund.github.io/ntsportal/articles/using-ntsportal-front-end.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the NTSPortal front-end","text":"NTSPortal UI ntsportal.bafg.de built using Kibana platform (Documentation). allows interactive viewing data.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/using-ntsportal-front-end.html","id":"registration-and-user-access","dir":"Articles","previous_headings":"Introduction","what":"Registration and user access","title":"Using the NTSPortal front-end","text":"Access ntsportal.bafg.de currently restricted IP whitelisting still development. static IP addresses permitted must white-listed BfG. Signing access currently restricted German government offices. Please contact BfG information send request access ntsportal@bafg.de.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/using-ntsportal-front-end.html","id":"structure","dir":"Articles","previous_headings":"Introduction","what":"Structure","title":"Using the NTSPortal front-end","text":"homepage ntsportal.bafg.de series links left-hand side access different dashboards (pages different views data). homepage linked dashboards restricted annotated features, meaning non-target detections match Collective Spectral Library (CSL).","code":""},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/articles/using-ntsportal-front-end.html","id":"search-for-a-compound-in-the-database-and-view-spatial-distribution","dir":"Articles","previous_headings":"Quick-Start","what":"Search for a compound in the database and view spatial distribution","title":"Using the NTSPortal front-end","text":"homepage, follow link “Search substances”. Initially see full dataset (role access ) Use drop-menus top screen filter data compound interest using name, formula, CAS registry number, InChI-key, compound group filtering m/z. selected, table map filtered compound interest. hovering name compound, “+” button appear, provide “drilldowns” – links dashboards view selected compound different data. example, one can view time series selected compound sites time series data available.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/articles/using-ntsportal-front-end.html","id":"view-time-series-of-a-compound-in-daily-monthly-yearly-samples","dir":"Articles","previous_headings":"Quick-Start","what":"View time series of a compound in daily, monthly, yearly samples","title":"Using the NTSPortal front-end","text":"two dashboards viewing time series data, one surface water samples, suspended particulate matter (SPM). view time series compounds found SPM extracts, follow link “Time series SPM” homepage time series SPM page, user can select compound drop-menu see changes relative peak area compound (relative internal standard) time station.","code":""},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/articles/using-ntsportal-front-end.html","id":"how-kibana-sees-the-data","dir":"Articles","previous_headings":"Concepts","what":"How Kibana sees the data","title":"Using the NTSPortal front-end","text":"dashboards views dataset available current role. user assigned role specific data access rights. data visible . data automatically trimmed minimize latency. much data trimmed (summarized, e.g. averaging daily intensity monthly intensity) depends visualisation. data trimming averaging done ElasticSearch query time. Kibana receives trimmed averaged data ElasticSearch displays . dashboards search box filter data using KQL syntax. requires knowledge field names types data. left search box “+”-button filters can added graphically. right search box time selector, data can filtered time (sampling time, measurement time import time, depending dashboard) Within dashboards drop-menus can used filter data filters set, click “Refresh” send query database retrieve new data. plots allow user “hide” datapoints (e.g. clicking legend entry time series, selected series hidden). Note: fetch new data database. original query trimmed minimize latency, remain trimmed.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kevin S. Jewell. Author, maintainer.           Federal Institute Hydrology (BfG) Koblenz, Germany Ole Lessmann. Author.           Federal Institute Hydrology (BfG) Koblenz, Germany Jonas Skottnik. Author.           Federal Institute Hydrology (BfG) Koblenz, Germany Franziska Thron. Author.           Federal Institute Hydrology (BfG) Koblenz, Germany Arne Wick. Author.           Federal Institute Hydrology (BfG) Koblenz, Germany","code":""},{"path":"https://bafg-bund.github.io/ntsportal/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jewell, K., Thron, F., Schlüsener, M., Kramer, K., Scharrenbach, T., Fettig, ., Koschorreck, J., Schulte, C., Ternes, T., & Wick, . (2021). Ein Datenbankmodell für aggregierte Non-Target-Screening-Ergebnisse. Vom Wasser, 119(3), 94-96. https://doi.org/10.1002/vomw.202100020","code":"@Article{,   title = {Ein Datenbankmodell für aggregierte Non-Target-Screening-Ergebnisse},   journal = {Vom Wasser},   volume = {119},   number = {3},   pages = {94-96},   year = {2021},   author = {{Jewell} and Kevin S. and {Thron} and {Franziska} and {Schlüsener} and {Michael} and {Kramer} and {K.} and {Scharrenbach} and {T.} and {Fettig} and {I.} and {Koschorreck} and {J.} and {Schulte} and {C.} and {Ternes} and Thomas A. and {Wick} and {Arne}}, }"},{"path":"https://bafg-bund.github.io/ntsportal/index.html","id":"ntsportal","dir":"","previous_headings":"","what":"NTSPortal database backend. Federal Institute of Hydrology, Koblenz, Germany","title":"NTSPortal database backend. Federal Institute of Hydrology, Koblenz, Germany","text":"goal ntsportal provide database online dashboard non-target-screening (based LC/GC-HRMS measurements) surface waters. system designed archive processed data carry simple data analysis online dashboards. detailed statistical analysis, API can used accessing data scripts. system currently uses Elasticsearch DBMS. R-package used processing data building database. included scripts automated data processing use ntsworkflow. Latest information structure internal design ntsportal found wiki. German government agencies, access internally managed NTSPortal database available. Please contact authors Federal Institute Hydrology. repository includes back-end code open-source development purposes include environmental data.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/index.html","id":"project-funding","dir":"","previous_headings":"","what":"Project Funding","title":"NTSPortal database backend. Federal Institute of Hydrology, Koblenz, Germany","text":"project initiated research funding grant Federal Environment Agency (UBA, “Online Portal: Non-Target-Screening für die Umweltüberwachung der Zukunft” REFOPLAN 3720222010) continued funding provided research grant REFOPLAN 3723222020 (“Weiterentwicklung des Online Portals für die Umweltbeobactung der Zukunft”). Additional funding provided Federal Ministry Digital Transport Federal Ministry Environment Consumer Protection.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"NTSPortal database backend. Federal Institute of Hydrology, Koblenz, Germany","text":"Copyright 2025 Bundesanstalt für Gewässerkunde (Federal Institute Hydrology) ntsportal free software: can redistribute /modify terms GNU General Public License published Free Software Foundation, either version 3 License, (option) later version. ntsportal distributed hope useful, WITHOUT WARRANTY; without even implied warranty MERCHANTABILITY FITNESS PARTICULAR PURPOSE. See GNU General Public License details. received copy GNU General Public License along ntsportal. , see https://www.gnu.org/licenses/. use package derivative thereof, please cite work. cite work please use following citation run citation(\"ntsportal\"). Kevin S. Jewell, Ole Lessmann, Franziska Thron, Jonas Skottnik, Iris Tuchscherer, Arne Wick Thomas . Ternes (2025). ntsportal: Non-Target Screening Data Archive Distribution Tool. R package version 25.1","code":""},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/index.html","id":"installation-via-github","dir":"","previous_headings":"","what":"Installation via Github","title":"NTSPortal database backend. Federal Institute of Hydrology, Koblenz, Germany","text":"Create Github PAT Add , following line, ~/.Rprofile Restart R session Install ntsportal Install Python requirements","code":"Sys.setenv(GITHUB_PAT = \"<...>\") remotes::install_github(\"bafg-bund/ntsportal\") reticulate::virtualenv_install(requirements = fs::path_package(\"ntsportal\", \"pythonElasticComm\", \"requirements.txt\"))"},{"path":"https://bafg-bund.github.io/ntsportal/reference/addRawfiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Add new records for MS measurement files to msrawfiles index — addRawfiles","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"Add new records MS measurement files msrawfiles index","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/addRawfiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"","code":"addRawfiles(   rfIndex,   templateId,   newPaths,   newStart = \"filename\",   newStation = \"same_as_template\",   dirMeasurmentFiles = \"/srv/cifs-mounts/g2/G/G2/HRMS/Messdaten/\",   promptBeforeIngest = TRUE,   saveDirectory = getwd(),   newStationList = list(station = \"example_new_station\", loc = list(lat = 1.23456, lon =     1.23456), river = \"example_new_river\", gkz = 99999, km = 99999) )"},{"path":"https://bafg-bund.github.io/ntsportal/reference/addRawfiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"templateId ES-ID existing msrawfiles-record use template newPaths Character vector full paths new rawfiles added, must mzXML files. newStart Either \"filename\" (default), meaning extract start time filename provide start date 8 digit number \"YYYYMMDD\" newStation Either \"same_as_template\" (default), copy value template document, \"filename\", meaning extract station loc values code filename (compare docs msrawfiles index) \"newStationList\" add new station. See details. dirMeasurmentFiles Root directory original measurement files located. function look original (vendor) files directory . Must end \"/\". promptBeforeIngest user asked verify submission? (Default: TRUE). file called \"add-rawfiles-check.json\" created saveDirectory user can check make changes . See details \"making manual changes\". saveDirectory Location save temporary json file checking making manual changes. (defaults current working dir) newStationList List fields \"station\" \"loc\" optionally \"river\", \"gkz\" \"km\" add new station. see details rfindex index name rawfiles index","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/addRawfiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"Returns vector new ES-IDs generated imported documents","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/addRawfiles.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"Adding location information (`station` `loc` fields)   newStation can either \"same_as_template\", \"filename\" \"newStationList\". Using \"same_as_template\" means station location information copied template Using \"filename\" means use `dbas_station_regex` field index get station information   another record index. function use regex extract station code filename   search msrawfiles index records station code. unambiguous location found,   gather available location information use new record entry. option useful batch   added contains one station. Using \"newStationList\" means new fixed station name location passed (use list argument   \"newStationList\" fields \"station\" \"loc\" optionally \"river\", \"gkz\" \"km\") \"loc\" geopoint   fields \"lat\" \"lon\". Station river names lowercase spaces special   characters. station name use convention <river_town_position> position l, r m left,   right, middle. obvious town km known, use convention <river>_<km> station   name. neither town km known, use convention <river>_<description> description   indication location. Adding sample time information (`start` field) Using \"filename\" means sample time extracted filename. field `dbas_date_regex` used   find date sample file name. works conjunction `dbas_date_format`. `dbas_date_regex`   extracts text, `dbas_date_format` tells R interpret text. example, file name   `RH_pos_20170101.mzXML` uses date_regex `\"([20]*\\d6)\"` date_format `\"ymd\"`. `dbas_date_regex` uses   tidyverse regular expression syntax `stringr::str_match` function extract text referring   date. brackets indicate text extract can surrounded anchors. also possible   multiple brackets, text multiple brackets combined parsing. example file   `UEBMS_2024_002_Main_Kahl_Jan_pos_DDA.mzXML` can parsed date_regex `_(20\\d2)_.*_(\\w3)_pos`   date_format `ym`. `dbas_date_format` may one `\"ymd\"`, `\"dmy\"`, `\"ym\"` year-month `\"yy\"` just year. date   parsing done `lubridate`. Making manual changes Manual changes can made json one document added (minimize errors). Select \"c\"   promt (changes json saved). File storage locations location mzXML files stored given argument `newPaths`.`saveDirectory` json   file written . `dirMeasurmentFiles` used look original (non-converted) vendor files (e.g.,   wiff files) read measurement time (copied mzXML file using converters). Depending   number files uploaded, function can slow function look large   directory. improve performance, can tell function look smaller directory. files found   function add creation time mzXML file.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/addRawfiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"","code":"if (FALSE) { # \\dontrun{ library(ntsportal) connectNtsportal() rfindex <- \"ntsp_msrawfiles\" paths <- list.files(\"/beegfs/nts/ntsportal/msrawfiles/ulm/schwebstoff/dou_pos/\", \"^Ulm.*mzXML$\", full.names = TRUE) templateId <- findTemplateId(rfindex, blank = FALSE, pol = \"pos\", station = \"donau_ul_m\", matrix = \"spm\") addRawfiles(rfindex = rfindex, templateId = templateId, newPaths = paths) checkMsrawfiles()  # Files in batch have different sample location addRawfiles(rfindex, \"eIRBnYkBcjCrX8D7v4H5\", newFiles[4:17], newStation = \"filename\",  dirMeasurmentFiles = \"~/messdaten/sachsen/\")   # Addition of a new station addRawfiles(   rfindex, \"eIRBnYkBcjCrX8D7v4H5\", newFiles[15],    newStation = \"newStationList\",   newStationList = list(     station = \"pleisse_9\",     loc = list(lat = 51.251489, lon = 12.383758),     river = \"pleisse\",     km = 9,     gkz = 5666   ) )  } # }"},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeAliasAddress.html","id":null,"dir":"Reference","previous_headings":"","what":"Change alias of an index to a new index. — changeAliasAddress","title":"Change alias of an index to a new index. — changeAliasAddress","text":"delete previous alias","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeAliasAddress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change alias of an index to a new index. — changeAliasAddress","text":"","code":"changeAliasAddress(indexName, aliasName, closeAfter = FALSE)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeAliasAddress.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change alias of an index to a new index. — changeAliasAddress","text":"indexName Name index aliasName Name alias closeAfter logical, previous index, alias linked prior change, closed?","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeAliasAddress.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change alias of an index to a new index. — changeAliasAddress","text":"Passes response ES (acknowledged field, TRUE FALSE), invisibly","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfileFilename.html","id":null,"dir":"Reference","previous_headings":"","what":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","title":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","text":"function change filename path doc.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfileFilename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","text":"","code":"changeMsrawfileFilename(rfIndex, oldPath, newPath)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfileFilename.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","text":"rfIndex index name msrawfiles index oldPath original path newPath updated path","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfileFilename.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","text":"True (invisibly) successful","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfilePath.html","id":null,"dir":"Reference","previous_headings":"","what":"Change the path of one document in msrawfiles — changeMsrawfilePath","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"secure method changing path doc msrawfiles. Filename changed must remain .","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfilePath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"","code":"changeMsrawfilePath(rfIndex, oldPath, newPath, checkType = \"md5\")"},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfilePath.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"rfIndex index name rawfiles index oldPath Current path rawfiles index, file must exist (1 file) newPath New path, file must exist (1 file) checkType Method check files , either \"md5\" (default) \"filesize\"","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfilePath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"TRUE change successful (invisibly)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfilePath.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"files must exist making change. function takes time compares md5-checksums two files. large numbers files use filesize check.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/changeMsrawfilePath.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"","code":"if (FALSE) { # \\dontrun{ library(ntsportal) connectNtsportal()  ind <- \"ntsp_msrawfiles\" res <- esSearchPaged(ind, sort = \"path\", searchBody = list(query = list(regexp = list(path = \"/srv.*\"))), source = \"path\")$hits$hits partToRemove <- \"/srv/cifs-mounts/g2/G/G2/HRMS/Messdaten/\" paths <- sapply(res, function(x) x[[\"_source\"]]$path) oldPaths <- data.frame(oldPath = paths, relPath = sub(partToRemove, \"\", paths)) relPaths <- list.files(\"/beegfs/nts/ntsportal/msrawfiles\", recursive = T) newPaths <- data.frame(   newPath = paste0(\"/beegfs/nts/ntsportal/msrawfiles/\", relPaths),   relPath = relPaths )  oldAndNewPaths <- merge(oldPaths, newPaths, all.x = T, by = \"relPath\")  for (i in 1:nrow(oldAndNewPaths)) {   changeMsrawfilePath(ind, oldAndNewPaths$oldPath[i], oldAndNewPaths$newPath[i], checkType = \"filesize\")   } } # }"},{"path":"https://bafg-bund.github.io/ntsportal/reference/checkMsrawfiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Check an msrawfile index for validity — checkMsrawfiles","title":"Check an msrawfile index for validity — checkMsrawfiles","text":"function connects elasticsearch checks given msrawfiles index according current validation routine.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/checkMsrawfiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check an msrawfile index for validity — checkMsrawfiles","text":"","code":"checkMsrawfiles(indexName = \"ntsp_msrawfiles\")"},{"path":"https://bafg-bund.github.io/ntsportal/reference/checkMsrawfiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check an msrawfile index for validity — checkMsrawfiles","text":"indexName default: ntsp_msrawfiles","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/checkMsrawfiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check an msrawfile index for validity — checkMsrawfiles","text":"TRUE","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/checkPngAvailability.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that PNGs for structural formulae are consistent with the spectral library — checkPngAvailability","title":"Check that PNGs for structural formulae are consistent with the spectral library — checkPngAvailability","text":"Check PNGs structural formulae consistent spectral library","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/checkPngAvailability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that PNGs for structural formulae are consistent with the spectral library — checkPngAvailability","text":"","code":"checkPngAvailability(databasePath, targetDir)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/checkPngAvailability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that PNGs for structural formulae are consistent with the spectral library — checkPngAvailability","text":"databasePath Path spectral library (sqlite) targetDir Path PNGs stored","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/connectNtsportal.html","id":null,"dir":"Reference","previous_headings":"","what":"Set ElasticSearch credentials and create ElasticSearch connection object — connectNtsportal","title":"Set ElasticSearch credentials and create ElasticSearch connection object — connectNtsportal","text":"credentials available, create \"escon\" connection object global environment use functions. Otherwise ask input credentials (interactive use). function uses keyring package store retrieve credentials. working Linux console, 'file' backend must used, see https://keyring.r-lib.org/reference/backends.html. can set Sys.setenv(\"R_KEYRING_BACKEND\" = \"file\")","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/connectNtsportal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set ElasticSearch credentials and create ElasticSearch connection object — connectNtsportal","text":"","code":"connectNtsportal()"},{"path":"https://bafg-bund.github.io/ntsportal/reference/convertToRecord.dbasResult.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a dbasResult to a list of featureRecords — convertToRecord.dbasResult","title":"Convert a dbasResult to a list of featureRecords — convertToRecord.dbasResult","text":"Convert dbasResult list featureRecords","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/convertToRecord.dbasResult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a dbasResult to a list of featureRecords — convertToRecord.dbasResult","text":"","code":"# S3 method for class 'dbasResult' convertToRecord(scanResult, msrawfileRecords)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/convertToRecord.dbasResult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a dbasResult to a list of featureRecords — convertToRecord.dbasResult","text":"","code":"if (FALSE) { # \\dontrun{ dbComm <- getDbComm() recs <- getTableAsRecords(   dbComm,    \"ntsp25.1_msrawfiles\",    searchBlock = list(query = list(regexp = list(filename = \"Des_.._.._pos.mzXML\"))),    newMsrawfilesRecord ) recsBlanks <- getTableAsRecords(   dbComm,    \"ntsp25.1_msrawfiles\",    searchBlock = list(query = list(regexp = list(path = \".*mud_pos/BW.*\"))),    newMsrawfilesRecord ) res <- scanBatchDbas(c(recs, recsBlanks), \"Methyltriphenylphosphonium\") featureRecs <- convertToRecord(res, c(recs, recsBlanks)) } # }"},{"path":"https://bafg-bund.github.io/ntsportal/reference/createAllStructures.html","id":null,"dir":"Reference","previous_headings":"","what":"Create images of structural formulas for display in Kibana dashboard — createAllStructures","title":"Create images of structural formulas for display in Kibana dashboard — createAllStructures","text":"Create images structural formulas display Kibana dashboard","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/createAllStructures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create images of structural formulas for display in Kibana dashboard — createAllStructures","text":"","code":"createAllStructures(databasePath, targetDir)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/createAllStructures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create images of structural formulas for display in Kibana dashboard — createAllStructures","text":"databasePath Path spectral library (sqlite) targetDir Path PNGs stored","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/createAllStructures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create images of structural formulas for display in Kibana dashboard — createAllStructures","text":"return value","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/createBackupMsrawfiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a backup of an msrawfiles index — createBackupMsrawfiles","title":"Create a backup of an msrawfiles index — createBackupMsrawfiles","text":"create backup index current date name (<msrawfilesName>_backup_<YYYYMMDD>). overwrite index unless overwrite = TRUE. backup index immediately closed interfere.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/createBackupMsrawfiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a backup of an msrawfiles index — createBackupMsrawfiles","text":"","code":"createBackupMsrawfiles(msrawfilesName, overwrite = FALSE)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/createBackupMsrawfiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a backup of an msrawfiles index — createBackupMsrawfiles","text":"msrawfilesName name index back overwrite logical, existing index overwritten (default false)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/createBackupMsrawfiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a backup of an msrawfiles index — createBackupMsrawfiles","text":"returns name new table","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningNewBatches.html","id":null,"dir":"Reference","previous_headings":"","what":"DBAS process all measurement files which have not yet been processed — dbaScreeningNewBatches","title":"DBAS process all measurement files which have not yet been processed — dbaScreeningNewBatches","text":"determine files yet processed, function collects directories msrawfiles looks feature indices see missing. TEMP TEST. TEMP TEST 2.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningNewBatches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DBAS process all measurement files which have not yet been processed — dbaScreeningNewBatches","text":"","code":"dbaScreeningNewBatches(msrawfileIndex, saveDirectory, numParallel = 1)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningNewBatches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DBAS process all measurement files which have not yet been processed — dbaScreeningNewBatches","text":"msrawfileIndex Name index processing information stored saveDirectory Location SLURM job files saved numParallel local parallel processing via future","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningOneBatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Process one batch of msrawfile records — dbaScreeningOneBatch","title":"Process one batch of msrawfile records — dbaScreeningOneBatch","text":"Process one batch msrawfile records","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningOneBatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process one batch of msrawfile records — dbaScreeningOneBatch","text":"","code":"dbaScreeningOneBatch(msrawfileRecords, saveDirectory)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningSelectedBatches.html","id":null,"dir":"Reference","previous_headings":"","what":"DBAS process selected measurement files via batch directory — dbaScreeningSelectedBatches","title":"DBAS process selected measurement files via batch directory — dbaScreeningSelectedBatches","text":"Choose batches process selecting directory measurement files stored.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningSelectedBatches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DBAS process selected measurement files via batch directory — dbaScreeningSelectedBatches","text":"","code":"dbaScreeningSelectedBatches(   msrawfileIndex,   batchDirs,   saveDirectory,   numParallel = 1 )"},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningSelectedBatches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DBAS process selected measurement files via batch directory — dbaScreeningSelectedBatches","text":"msrawfileIndex Name index processing information stored batchDirs Directory measurement files (recursive, multiple permitted) saveDirectory Location SLURM job files saved numParallel local parallel processing via future","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningSelectedBatchesSlurm.html","id":null,"dir":"Reference","previous_headings":"","what":"DBAS process batches by directory using the workload manager — dbaScreeningSelectedBatchesSlurm","title":"DBAS process batches by directory using the workload manager — dbaScreeningSelectedBatchesSlurm","text":"Choose batches process selecting directory measurement files stored. function create necessary files submission job workflow manager SLURM.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningSelectedBatchesSlurm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DBAS process batches by directory using the workload manager — dbaScreeningSelectedBatchesSlurm","text":"","code":"dbaScreeningSelectedBatchesSlurm(   msrawfileIndex,   batchDirs,   saveDirectory,   email )"},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningSelectedBatchesSlurm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DBAS process batches by directory using the workload manager — dbaScreeningSelectedBatchesSlurm","text":"msrawfileIndex Name index processing information stored batchDirs Directory measurement files (recursive, multiple permitted) saveDirectory Location SLURM job files saved email Address SLURM notifications","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningSelectedBatchesSlurm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"DBAS process batches by directory using the workload manager — dbaScreeningSelectedBatchesSlurm","text":"Three files created, records files process, organized batches (.RDS); R script SLURM needs run, SLURM job file. command needed start process given message (may need switch SLURM-enabled server).","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/dbaScreeningSelectedBatchesSlurm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DBAS process batches by directory using the workload manager — dbaScreeningSelectedBatchesSlurm","text":"","code":"if (FALSE) { # \\dontrun{ userEmail <- \"example@bafg.de\" dirResults <- \"processingResults\" msrawfileIndexName <- \"ntsp25.1_msrawfiles\" library(ntsportal) connectNtsportal() file.remove(list.files(dirResults, f = T))  dbaScreeningSelectedBatchesSlurm(   msrawfileIndex = msrawfileIndexName,   batchDirs = \"/root/dir/all/msrawfiles\",   saveDirectory = dirResults,   email = userEmail ) } # }"},{"path":"https://bafg-bund.github.io/ntsportal/reference/DbComm-class.html","id":null,"dir":"Reference","previous_headings":"","what":"DbComm interface — DbComm-class","title":"DbComm interface — DbComm-class","text":"DbComm interface","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/deleteTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a table — deleteTable","title":"Delete a table — deleteTable","text":"Delete table","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/deleteTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a table — deleteTable","text":"","code":"deleteTable(dbComm, tableName)  # S4 method for class 'PythonDbComm' deleteTable(dbComm, tableName)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/deleteTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a table — deleteTable","text":"dbComm DbComm connection object tableName Name table database","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/esSearchPaged.html","id":null,"dir":"Reference","previous_headings":"","what":"Get search results for more than 10000 docs by pagination. — esSearchPaged","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"local function","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/esSearchPaged.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"","code":"esSearchPaged(   indexName,   searchBody = list(query = list(match_all = stats::setNames(list(), character(0)))),   sort,   totalSize = Inf,   ... )"},{"path":"https://bafg-bund.github.io/ntsportal/reference/esSearchPaged.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"indexName Name ElasticSearch index searchBody search body, default return docs sort Sort argument passed onto elastic::Search. Defines field results sorted (best unique docs avoid ties) currently can one field may '_id'. totalSize  ... arguments elastic::Search, asdf argument work now.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/esSearchPaged.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"ElasticSearch API response list","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/esSearchPaged.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"","code":"if (FALSE) { # \\dontrun{ connectNtsportal() res <- esSearchPaged(\"ntsp25.1_dbas*\", searchBody = list(query = list(term = list(station = \"mosel_ko_r\"))),    source = c(\"name\", \"inchikey\", \"pol\", \"start\", \"duration\", \"area\"), sort = \"mz\")  # Convert the returned list to a data.frame temp <- lapply(res$hits$hits, function(x) as.data.frame(x[[\"_source\"]])) df <- plyr::rbind.fill(temp) } # }"},{"path":"https://bafg-bund.github.io/ntsportal/reference/es_error_handler.html","id":null,"dir":"Reference","previous_headings":"","what":"Handle errors from ElasticSearch — es_error_handler","title":"Handle errors from ElasticSearch — es_error_handler","text":"Errors ElasticSearch returned package 'elastic' text. function take error condition take appropriate action.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/es_error_handler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handle errors from ElasticSearch — es_error_handler","text":"","code":"es_error_handler(thisCnd)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/es_error_handler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handle errors from ElasticSearch — es_error_handler","text":"thisCnd Error condition thrown `tryCatch` context","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/es_error_handler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handle errors from ElasticSearch — es_error_handler","text":"return value","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/findTemplateId.html","id":null,"dir":"Reference","previous_headings":"","what":"Get ID based on search parameters — findTemplateId","title":"Get ID based on search parameters — findTemplateId","text":"Get ID based search parameters","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/findTemplateId.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get ID based on search parameters — findTemplateId","text":"","code":"findTemplateId(   rfIndex,   blank = FALSE,   pol = \"pos\",   station = \"rhein_ko_l\",   matrix = \"spm\",   duration = 365 )"},{"path":"https://bafg-bund.github.io/ntsportal/reference/findTemplateId.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get ID based on search parameters — findTemplateId","text":"rfIndex index name rawfiles index pol Either \"pos\" \"neg\", default \"pos\" station Station ID name matrix character default \"spm\" duration numeric, default 365 isBlank boolean default FALSE","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/findTemplateId.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get ID based on search parameters — findTemplateId","text":"ES-ID template record msrawfiles index","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getDbComm.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a DbComm interface object using the constructor given by the ntsportal.dbComm option — getDbComm","title":"Make a DbComm interface object using the constructor given by the ntsportal.dbComm option — getDbComm","text":"Make DbComm interface object using constructor given ntsportal.dbComm option","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getDbComm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a DbComm interface object using the constructor given by the ntsportal.dbComm option — getDbComm","text":"","code":"getDbComm()"},{"path":"https://bafg-bund.github.io/ntsportal/reference/getNrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the number of rows in a table — getNrow","title":"Get the number of rows in a table — getNrow","text":"Get number rows table","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getNrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the number of rows in a table — getNrow","text":"","code":"getNrow(dbComm, tableName, searchBlock = list())  # S4 method for class 'PythonDbComm' getNrow(dbComm, tableName, searchBlock = list())"},{"path":"https://bafg-bund.github.io/ntsportal/reference/getNrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the number of rows in a table — getNrow","text":"dbComm DbComm connection object tableName Name table database searchBlock list coercible json Elasticsearch Search API (Query DSL)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getNrow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the number of rows in a table — getNrow","text":"integer","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getTableAsRecords.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a table as a list of ntspRecords — getTableAsRecords","title":"Get a table as a list of ntspRecords — getTableAsRecords","text":"Get table list ntspRecords","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getTableAsRecords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a table as a list of ntspRecords — getTableAsRecords","text":"","code":"getTableAsRecords(   dbComm,   tableName,   searchBlock = list(),   recordConstructor = newNtspRecord )"},{"path":"https://bafg-bund.github.io/ntsportal/reference/getTableAsRecords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a table as a list of ntspRecords — getTableAsRecords","text":"dbComm DbComm connection object tableName Name table database searchBlock list coercible json Elasticsearch Search API (Query DSL) recordConstructor function construct new records","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getTableAsRecords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a table as a list of ntspRecords — getTableAsRecords","text":"list ntspRecord objects","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getTableAsTibble.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a table as a tibble — getTableAsTibble","title":"Get a table as a tibble — getTableAsTibble","text":"Get table tibble","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getTableAsTibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a table as a tibble — getTableAsTibble","text":"","code":"getTableAsTibble(dbComm, tableName, searchBlock = list())"},{"path":"https://bafg-bund.github.io/ntsportal/reference/getTableAsTibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a table as a tibble — getTableAsTibble","text":"dbComm DbComm connection object tableName Name table database searchBlock list coercible json Elasticsearch Search API (Query DSL)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/getTableAsTibble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a table as a tibble — getTableAsTibble","text":"tibble","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/ingest.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest of json.gz files into Elasticsearch — ingest","title":"Ingest of json.gz files into Elasticsearch — ingest","text":"processing output gzip-compressed json file batch (one large batches). ingested NTSPortal Elasticsearch.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/ingest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest of json.gz files into Elasticsearch — ingest","text":"","code":"ingest(path)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/ingest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest of json.gz files into Elasticsearch — ingest","text":"path Path single json.gz file directory json.gz files.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/ingest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ingest of json.gz files into Elasticsearch — ingest","text":"list one top-level entry per batch (json.gz file). second level one entry per alias contains character vector index name associated alias.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/isTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Does a table exist? — isTable","title":"Does a table exist? — isTable","text":"table exist?","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/isTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Does a table exist? — isTable","text":"","code":"isTable(dbComm, tableName)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/isTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Does a table exist? — isTable","text":"dbComm DbComm connection object tableName Name table database","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/isTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Does a table exist? — isTable","text":"logical, true table exists","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/msrawfilesSetVersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Change msrawfiles to a new version — msrawfilesSetVersion","title":"Change msrawfiles to a new version — msrawfilesSetVersion","text":"Change msrawfiles new version","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/msrawfilesSetVersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change msrawfiles to a new version — msrawfilesSetVersion","text":"","code":"msrawfilesSetVersion(msrawfilesName, version)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/msrawfilesSetVersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change msrawfiles to a new version — msrawfilesSetVersion","text":"msrawfilesName Name msrawfiles table version New version number","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/msrawfilesSetVersion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change msrawfiles to a new version — msrawfilesSetVersion","text":"","code":"if (FALSE) { # \\dontrun{ msrawfilesSetVersion(\"msrawfiles\", \"25.1\") } # }"},{"path":"https://bafg-bund.github.io/ntsportal/reference/ntsportal-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ntsportal: NTSPortal database backend. Federal Institute of Hydrology, Koblenz, Germany — ntsportal-package","title":"ntsportal: NTSPortal database backend. Federal Institute of Hydrology, Koblenz, Germany — ntsportal-package","text":"package provides functionality building managing NTSPortal database.","code":""},{"path":[]},{"path":"https://bafg-bund.github.io/ntsportal/reference/ntsportal-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ntsportal: NTSPortal database backend. Federal Institute of Hydrology, Koblenz, Germany — ntsportal-package","text":"Maintainer: Kevin S. Jewell jewell@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) Authors: Ole Lessmann lessmann@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) Jonas Skottnik skottnik@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) Franziska Thron thron@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) Arne Wick wick@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/ntsportal.html","id":null,"dir":"Reference","previous_headings":"","what":"ntsportal: A package for non-target data management — ntsportal","title":"ntsportal: A package for non-target data management — ntsportal","text":"ntsportal: package non-target data management","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/ping.html","id":null,"dir":"Reference","previous_headings":"","what":"Test the DB-Connection — ping","title":"Test the DB-Connection — ping","text":"Test DB-Connection","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/ping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test the DB-Connection — ping","text":"","code":"ping(dbComm)  # S4 method for class 'PythonDbComm' ping(dbComm)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/ping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test the DB-Connection — ping","text":"dbComm DbComm connection object","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/ping.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test the DB-Connection — ping","text":"TRUE connection active","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/PythonDbComm-class.html","id":null,"dir":"Reference","previous_headings":"","what":"A DbComm interface using the python back-end — PythonDbComm-class","title":"A DbComm interface using the python back-end — PythonDbComm-class","text":"DbComm interface using python back-end","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/PythonDbComm-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"A DbComm interface using the python back-end — PythonDbComm-class","text":"client python elasticsearch client object dsl python elasticsearch.dsl import module","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/PythonDbComm.html","id":null,"dir":"Reference","previous_headings":"","what":"Create connection to elasticsearch — PythonDbComm","title":"Create connection to elasticsearch — PythonDbComm","text":"Create connection elasticsearch","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/PythonDbComm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create connection to elasticsearch — PythonDbComm","text":"","code":"PythonDbComm(ring = \"ntsportal\")"},{"path":"https://bafg-bund.github.io/ntsportal/reference/PythonDbComm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create connection to elasticsearch — PythonDbComm","text":"ring","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/PythonDbComm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create connection to elasticsearch — PythonDbComm","text":"PythonDbComm","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/removeRedundantPngs.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete redundant PNGs — removeRedundantPngs","title":"Delete redundant PNGs — removeRedundantPngs","text":"Delete redundant PNGs","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/removeRedundantPngs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete redundant PNGs — removeRedundantPngs","text":"","code":"removeRedundantPngs(databasePath, targetDir)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/removeRedundantPngs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete redundant PNGs — removeRedundantPngs","text":"databasePath Path spectral library (sqlite) targetDir Path PNGs stored","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/resetConnectionCredentials.html","id":null,"dir":"Reference","previous_headings":"","what":"Create connection with new credentials — resetConnectionCredentials","title":"Create connection with new credentials — resetConnectionCredentials","text":"Create connection new credentials","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/resetConnectionCredentials.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create connection with new credentials — resetConnectionCredentials","text":"","code":"resetConnectionCredentials()"},{"path":"https://bafg-bund.github.io/ntsportal/reference/scanBatchDbas.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a list of msrawfileRecords — scanBatchDbas","title":"Process a list of msrawfileRecords — scanBatchDbas","text":"Process list msrawfileRecords","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/scanBatchDbas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a list of msrawfileRecords — scanBatchDbas","text":"","code":"scanBatchDbas(records, compsToProcess = NULL, showProgress = FALSE)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/scanBatchDbas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a list of msrawfileRecords — scanBatchDbas","text":"records list msrawfileRecords compsToProcess Character vector compounds names (Default compounds spectral library) showProgress logical. Show progress bar (interacte use, default false)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/scanBatchDbas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a list of msrawfileRecords — scanBatchDbas","text":"dbasResult object (list 7 tables) including peakList, reintegrationResults etc.","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/scanBatchDbas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process a list of msrawfileRecords — scanBatchDbas","text":"","code":"if (FALSE) { # \\dontrun{ dbComm <- getDbComm() recs <- getTableAsRecords(   dbComm,    \"ntsp25.1_msrawfiles\",    searchBlock = list(query = list(regexp = list(filename = \"Des_19_.._pos.mzXML\"))),   newMsrawfilesRecord ) recsBlanks <- getTableAsRecords(   dbComm,    \"ntsp25.1_msrawfiles\",    searchBlock = list(query = list(regexp = list(path = \".*mud_pos/BW.*\"))),    newMsrawfilesRecord ) res <- scanBatchDbas(c(recs, recsBlanks), \"Methyltriphenylphosphonium\") } # }"},{"path":"https://bafg-bund.github.io/ntsportal/reference/setCredNonInteractive.html","id":null,"dir":"Reference","previous_headings":"","what":"Set credentials for accessing NTSPortal ElasticSearch — setCredNonInteractive","title":"Set credentials for accessing NTSPortal ElasticSearch — setCredNonInteractive","text":"Set credentials accessing NTSPortal ElasticSearch","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/setCredNonInteractive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set credentials for accessing NTSPortal ElasticSearch — setCredNonInteractive","text":"","code":"setCredNonInteractive(ring = \"ntsportal\", usr = character(), pwd = character())"},{"path":"https://bafg-bund.github.io/ntsportal/reference/setCredNonInteractive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set credentials for accessing NTSPortal ElasticSearch — setCredNonInteractive","text":"ring Keyring name, change default usr username, enter manually non-interactive use pwd password, enter manually non-interactive use","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/setValueInField.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the value of a field in a table — setValueInField","title":"Set the value of a field in a table — setValueInField","text":"Set value field table","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/setValueInField.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the value of a field in a table — setValueInField","text":"","code":"setValueInField(dbComm, tableName, field, value, searchBlock = list())"},{"path":"https://bafg-bund.github.io/ntsportal/reference/setValueInField.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the value of a field in a table — setValueInField","text":"dbComm DbComm connection object tableName Name table database field table column change value value set field searchBlock list coercible json Elasticsearch Search API (Query DSL)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/updateLinearRegressionTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Update the ","title":"Update the ","text":"analysis table shows slope linear regression model compound station yearly composite samples can computed yearly composite samples SPM upb dbas index","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/updateLinearRegressionTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update the ","text":"","code":"updateLinearRegressionTable(sourceTableName)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/updateLinearRegressionTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update the ","text":"sourceTableName Table ntsportal analyzed (dbas_upb)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/updateSpectralLibrary.html","id":null,"dir":"Reference","previous_headings":"","what":"Update the CSL spectral library on ntsportal — updateSpectralLibrary","title":"Update the CSL spectral library on ntsportal — updateSpectralLibrary","text":"Update CSL spectral library ntsportal","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/updateSpectralLibrary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update the CSL spectral library on ntsportal — updateSpectralLibrary","text":"","code":"updateSpectralLibrary(rfTableName, specLibTableName)"},{"path":"https://bafg-bund.github.io/ntsportal/reference/updateSpectralLibrary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update the CSL spectral library on ntsportal — updateSpectralLibrary","text":"rfTableName Name msrawfiles table specLibTableName Name new spectral library table (old table overwritten)","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/validateRecord.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate that a record is correctly formated — validateRecord","title":"Validate that a record is correctly formated — validateRecord","text":"Validate record correctly formated","code":""},{"path":"https://bafg-bund.github.io/ntsportal/reference/validateRecord.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate that a record is correctly formated — validateRecord","text":"","code":"validateRecord(record)  # S3 method for class 'msrawfilesRecord' validateRecord(record)  # S3 method for class 'featureRecord' validateRecord(record)"}]
