[{"path":"http://r.bafg.de/articles/Add-measurement-file-to-msrawfiles.html","id":"step-by-step-guide-to-using-addrawfiles","dir":"Articles","previous_headings":"","what":"Step-by-step guide to using addRawfiles()","title":"Adding measurement files to msrawfiles","text":"Install newest version ntsportal, including Python requirements. First, create backup msrawfiles. Use function createBackupMsrawfiles(), backup named ntsp25.2_msrawfiles_backup_<YYYYMMDD> created. Find new mzXML measurement files - e.g. Windows Explorer necessary, move files correct storage location1. batch (measurement sequence) stored directory. batches become larger ca. 60 files split several batches. Go RStudio Get ID document use template files want add either using Dev Tools console findTemplateId(): Get vector paths files added. case positive measurement files samples (blanks) Run addRawfiles() Use dirMeasurmentFiles argument specify look original (vendor format) measurement files (root directory sufficient). used get measurement time since always written mzXML file, e.g. converting wiff files2. Check add-rawfiles-check.json (e.g., start, filename, pol blank fields) want make changes add-rawfiles-check.json, can accepted adding one file (run addRawfiles() just one file newPaths argument) prompted console, enter y okay / n okay / c made changes JSON (remember save JSON beforehand) Add next set files, example blanks batch added: Check coherency msrawfiles. step takes minutes, recommended files loaded.","code":"library(ntsportal) connectNtsportal()  rfIndex <- \"ntsp25.2_msrawfiles\"  createBackupMsrawfiles(rfIndex) templateId <- findTemplateId(rfIndex, blank = F, pol =\"pos\", station = \"rhein_ko_l\", matrix = \"water\", duration = 1) pathsToAdd <- list.files(   path = \"/beegfs/nts/ntsportal/msrawfiles/koblenz/wasser/2024/202406/pos/\",    pattern = \"RH_pos_\\\\d{8}\\\\.mzXML\", full.names = TRUE) addRawfiles(   rfIndex = rfIndex,    templateId = templateId,    newPaths = pathsToAdd,   dirMeasurmentFiles = \"~/Messdaten/koblenz/wasser/2024/202406/pos/wiff/\" ) blanksToAdd <- list.files(   path = \"/beegfs/nts/ntsportal/msrawfiles/koblenz/wasser/2024/202406/pos/\",    pattern = \"MQ\", full.names = TRUE) blankID <-  findTemplateId(rfIndex, blank = TRUE, pol =\"pos\", station = \"rhein_ko_l\", matrix = \"water\", duration = 1) addRawfiles(   rfIndex = rfIndex,    templateId = blankID,    newPaths = blanksToAdd,   dirMeasurmentFiles = \"~/Messdaten/koblenz/wasser/2024/202406/pos/wiff/\" ) checkMsrawfiles(rfIndex)"},{"path":"http://r.bafg.de/articles/Add-measurement-file-to-msrawfiles.html","id":"function-description","dir":"Articles","previous_headings":"","what":"Function description","title":"Adding measurement files to msrawfiles","text":"function designed make adding new files msrawfiles quick error-free possible. works copying existing documents msrawfiles templates changing certain fields.","code":""},{"path":[]},{"path":"http://r.bafg.de/articles/Add-measurement-file-to-msrawfiles.html","id":"the-files-being-added-have-different-measurement-locations","dir":"Articles","previous_headings":"Special cases","what":"The files being added have different measurement locations","title":"Adding measurement files to msrawfiles","text":"addRawfiles() can dynamically change location entry based location encoded filename. field dbas_station_regex template document used find documents matching location existing entries msrawfiles. location information copied documents (station, loc, river, km gkz fields). Use newStation = \"filename\" copy location information entries Example filename: OBF34910_20230821_Zschopau_pos.mzXML Example dbas_station_regex: ^(OBF\\\\d{5})_","code":"addRawfiles(rfindex, \"eIRBnYkBcjCrX8D7v4H5\", newFiles[4:17], newStation = \"filename\",               dirMeasurmentFiles = \"~/messdaten/sachsen/\")"},{"path":"http://r.bafg.de/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"aggregation-terms","dir":"Articles","previous_headings":"","what":"Aggregation: terms","title":"Aggregations with ElasticSearch Query DSL","text":"terms aggregation groups documents returned query buckets according keyword boolean field. Aggregations can nested, bucket can successively split sub-buckets. code search two stations split results station, polarity blank yes/via three nested terms aggregations. Note: terms query terms aggregation two different things. first filters results multiple possible values (keyword field), second splits filtered results (documents) buckets based keyword field. example three terms aggregations nested , say, station bucket split polarity buckets split field blank (boolean).","code":"GET ntsp_msrawfiles/_search?size=0  // Size is 0, meaning no doc sources are returned {   \"query\": {     \"terms\": {                 // terms query       \"station\": [         \"donau_ul_m\",         \"saale_wettin_m\"       ]     }   },    \"aggs\": {     \"messstellen\": {           // just a variable name you give it (can be anything)       \"terms\": {               // terms aggregation         \"field\": \"station\"       },       \"aggs\": {         \"polaritaet\": {           \"terms\": {           // terms aggregation             \"field\": \"pol\"           },           \"aggs\": {             \"methoden_blanks\": {               \"terms\": {       // terms aggregation                 \"field\": \"blank\"               }             }           }         }       }     }   } }"},{"path":"http://r.bafg.de/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"overview-of-all-compounds","dir":"Articles","previous_headings":"","what":"Overview of all compounds","title":"Aggregations with ElasticSearch Query DSL","text":"example also show polarities matrices compound found. Explanations:ntsp25.2_dbas* – index pattern, indices starting character string selected.","code":"GET ntsp25.2_dbas*/_search?size=0  {                                 // Since there is no query, all docs are used for the aggs   \"aggs\": {     \"compounds\": {                       \"terms\": {         \"field\": \"name\",          // split by compound name         \"size\": 1000              // Default is 10, must be set higher for 'name' field       },       \"aggs\": {         \"pols\": {                           \"terms\": {             \"field\": \"pol\"      // There are only 2 polarities           },           \"aggs\": {             \"matrices\": {                      \"terms\": {                 \"field\": \"matrix\"                 }             }           }         }       }     }   } }"},{"path":"http://r.bafg.de/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"bucket-aggregations-and-metric-aggregations","dir":"Articles","previous_headings":"","what":"Bucket aggregations and metric aggregations","title":"Aggregations with ElasticSearch Query DSL","text":"example term query used filter data suspended particulate matter (spm). detections binned station name (terms bucket aggregation) station latest file upload time returned (max metric aggregation).","code":"GET ntsp_msrawfiles/_search?size=0 {   \"query\": {     \"term\": {       \"matrix\": {         \"value\": \"spm\"       }     }   },   \"aggs\": {     \"messstellen\": {       \"terms\": {         \"field\": \"station\"       },       \"aggs\": {         \"neuste\": {           \"max\": {             \"field\": \"date_import\"           }         }       }     }   } }"},{"path":"http://r.bafg.de/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"combining-aggregations-and-a-bool-query","dir":"Articles","previous_headings":"","what":"Combining aggregations and a bool query","title":"Aggregations with ElasticSearch Query DSL","text":"example query stations ulm wettin, blanks documents split station polarity","code":"GET ntsp_msrawfiles/_search?size=0 {   \"query\": {     \"bool\": {       \"must\": [         {           \"terms\": {             \"station\": [               \"donau_ul_m\",               \"saale_wettin_m\"             ]           }         },         {           \"term\": {             \"blank\": {               \"value\": \"false\"             }           }         }       ]     }   },   \"aggs\": {     \"kontrolle\": {       \"terms\": {         \"field\": \"station\"       },       \"aggs\": {         \"polaritaet\": {           \"terms\": {             \"field\": \"pol\"           }         }       }     }   } }"},{"path":"http://r.bafg.de/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"aggregation-geotile_grid","dir":"Articles","previous_headings":"","what":"Aggregation: geotile_grid","title":"Aggregations with ElasticSearch Query DSL","text":"example documents searched matching pattern split coordinates (geopoint) split results station precision can set maximum since within station coordinates must exactly .","code":"GET ntsp_msrawfiles/_search?size=0 {   \"query\": {     \"regexp\": {       \"station\": \".*NA\"     }   },   \"aggs\": {     \"stations\": {       \"terms\": {         \"field\": \"station\"       },       \"aggs\": {         \"locations\": {           \"geotile_grid\": {             \"field\": \"loc\",             \"precision\": 21,             \"size\": 10           }         }       }     }   } }"},{"path":"http://r.bafg.de/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"aggregation-cardinality","dir":"Articles","previous_headings":"","what":"Aggregation: cardinality","title":"Aggregations with ElasticSearch Query DSL","text":"cardinality aggregation counts number unique entries keyword field. example want split detections compound also want know many different compounds found database. two aggregations set parallel (nested).","code":"GET ntsp_dbas_upb/_search?size=0           {   \"aggs\": {                         // There are two different aggregations listed here     \"num_different_comps\": {        // Aggregation 1 determines the number of different compounds       \"cardinality\": {             \"field\": \"name\",         \"precision_threshold\": 1000 // default is 100, need to set it higher, ca. 400 different compounds       }     },     \"comps_buckets\": {              // Aggregation 2 splits docs into buckets by compound name       \"terms\": {                             \"field\": \"name\",         \"size\": 1000                       }     }   } }"},{"path":"http://r.bafg.de/articles/Aggregations-with-ElasticSearch-Query-DSL.html","id":"filtering-buckets-by-their-doc-counts","dir":"Articles","previous_headings":"","what":"Filtering buckets by their doc counts","title":"Aggregations with ElasticSearch Query DSL","text":"example buckets filtered compounds found 10 times total days compound found returned.","code":"GET ntsp_dbas_v231006_frame/_search?size=0 {   \"query\": {     \"term\": {       \"pol\": {         \"value\": \"pos\"       }     }   },   \"aggs\": {     \"comps\": {       \"terms\": {         \"field\": \"name\",         \"size\": 1000       },       \"aggs\": {         \"comps_selector\": {           \"bucket_selector\": {             \"buckets_path\": {               \"numSamplesPerComp\": \"_count\"             },             \"script\": \"params.numSamplesPerComp >= 10\"           }         },         \"samples\": {           \"date_histogram\": {             \"field\": \"start\",             \"calendar_interval\": \"1d\"           },           \"aggs\": {             \"days_selector\": {               \"bucket_selector\": {                 \"buckets_path\": {                   \"numSamplesPerDay\" : \"_count\"                 },                 \"script\": \"params.numSamplesPerDay > 0\"               }             }           }         }       }     },     \"files\": {       \"cardinality\": {         \"field\": \"filename\"       }     }   } }"},{"path":[]},{"path":"http://r.bafg.de/articles/Connecting-to-NTSPortal-API.html","id":"api-connection-getting-started","dir":"Articles","previous_headings":"","what":"API Connection, getting started","title":"Connecting to the NTSPortal Elasticsearch Search API from R or Python","text":"API called elastic.bafg.de. Users must 1) granted API access (please send request ntsportal@bafg.de) 2) must created API key ntsportal.bafg.de (Menu->Management->Stack Management->Security->API keys, ‘control security privileges’ must checked”) API documentation found . Detailed documentation available different search languages offered, e.g. Query DSL.","code":""},{"path":"http://r.bafg.de/articles/Connecting-to-NTSPortal-API.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Connecting to the NTSPortal Elasticsearch Search API from R or Python","text":"R-package elastic allows calls ElasticSearch API within R json data returned list data.frame. list can reformatted data.frame analysis R. best way get started test query kibana Dev Tools console copy query R run command . Since elastic longer maintained, recommended method use Python elasticsearch elasticsearch-dsl modules within R using reticulate. PythonDbComm class uses .","code":""},{"path":"http://r.bafg.de/articles/Connecting-to-NTSPortal-API.html","id":"storing-of-user-credentials","dir":"Articles","previous_headings":"Introduction","what":"Storing of user credentials","title":"Connecting to the NTSPortal Elasticsearch Search API from R or Python","text":"ntsportal::connectNtsportal() stores retrieves NTSPortal user credentials, uses keyring store username password.","code":""},{"path":"http://r.bafg.de/articles/Connecting-to-NTSPortal-API.html","id":"ignoring-ssl-verification","dir":"Articles","previous_headings":"Introduction","what":"Ignoring SSL verification","title":"Connecting to the NTSPortal Elasticsearch Search API from R or Python","text":"recommended, certificate error, can turn SSL verification:","code":""},{"path":"http://r.bafg.de/articles/Connecting-to-NTSPortal-API.html","id":"using-r-package-elastic","dir":"Articles","previous_headings":"Introduction > Ignoring SSL verification","what":"Using R package elastic","title":"Connecting to the NTSPortal Elasticsearch Search API from R or Python","text":"","code":"escon <- elastic::connect(   host = 'xxxx.bafg.de',    port = XXX, user=ec$user,    pwd  = ec$pwd,   transport_schema = \"https\",   ssl_verifypeer = FALSE )"},{"path":"http://r.bafg.de/articles/Connecting-to-NTSPortal-API.html","id":"using-python","dir":"Articles","previous_headings":"Introduction > Ignoring SSL verification","what":"using python","title":"Connecting to the NTSPortal Elasticsearch Search API from R or Python","text":"","code":"from elasticsearch import Elasticsearch def getDbClient(username, password, hostUrl):   es_client = Elasticsearch(         hosts=hostUrl,         basic_auth=(username, password),         verify_certs=False   )   return es_client"},{"path":"http://r.bafg.de/articles/Connecting-to-NTSPortal-API.html","id":"checking-your-ip-address","dir":"Articles","previous_headings":"","what":"Checking your IP address","title":"Connecting to the NTSPortal Elasticsearch Search API from R or Python","text":"check IP trying connect:","code":"library(rjson) fromJSON(readLines(\"http://api.hostip.info/get_json.php\", warn=F))$ip"},{"path":[]},{"path":[]},{"path":"http://r.bafg.de/articles/Dashboard-development.html","id":"front-end-logic","dir":"Articles","previous_headings":"Spectral library dashboard > Structural formula visualization","what":"Front-end logic","title":"Dashboard development and backend","text":"custom, Vega-lite Kibana visualization retrieves PNG image structural formula picture.ntsportal.bafg.de renders . correct structure chosen based first document provided Kibana search context. inchikey field extracted document used build URL points correct structure. example, Edetol https://picture.ntsportal.bafg.de/NSOXQYCFHDMMGV-UHFFFAOYSA-N.png.","code":""},{"path":"http://r.bafg.de/articles/Dashboard-development.html","id":"back-end-infrastructure","dir":"Articles","previous_headings":"Spectral library dashboard > Structural formula visualization","what":"Back-end infrastructure","title":"Dashboard development and backend","text":"PNGs written asynchronously ntsportal::createAllStructures() picture server. PNG files first saved designated folder synchronized automatically image server. createAllStructures() produces structural formulas compounds CSL PNGs. PNGs must updated function NTSPortal administrator new CSL version used NTSPortal. createAllStructures consists 4 steps: copy CSL databasePath created temporary directory. compound list extracted SQlite .db file help RSQlite package. SMILES code compound converted structural formula rcdk package (requires rJava). formulas exported .png files targetDir – best folder synchronized picture server, can accessed Kibana. file names InChiKeys substances.","code":""},{"path":"http://r.bafg.de/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"zugang","dir":"Articles","previous_headings":"","what":"Zugang","title":"Kurzanleitung zur ersten Nutzung","text":"Das NTS-Portal ist unter folgendem Link erreichbar: ntsportal.bafg.de Username und Passwort für neue Nutzer können per E-Mail beantragt werden: ntsportal mailbox","code":""},{"path":[]},{"path":"http://r.bafg.de/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"startseite","dir":"Articles","previous_headings":"Überblick und erste Möglichkeiten","what":"Startseite","title":"Kurzanleitung zur ersten Nutzung","text":"Der Link führt zur Startseite der Datenbank für annotierte Substanzen. Links finden sich Quicklinks zu verschiedenen Bereichen, der Mitte ein Überblick über die erfassten Daten und rechts eine Karte aller Messstationen für Wasser- (blau) und SPM-Proben (braun).","code":""},{"path":"http://r.bafg.de/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"tasks-search-for-substances","dir":"Articles","previous_headings":"Überblick und erste Möglichkeiten","what":"Tasks: Search for substances","title":"Kurzanleitung zur ersten Nutzung","text":"Über den Quicklink „Search substances” gelangt man zu einer Übersicht aller annotierten Substanzen allen Messstellen. Über die Dropdown Menüs unterhalb des Suchfelds kann man nach bestimmten Substanzen („Comp. name”), Summenformeln, CAS-Nummern oder auch Massenbereichen filtern. Es lassen sich auch mehrere Einträge den Dropdown Menüs anklicken, dass man z.B. mehrere Substanzen (hier: Benzotriazole, Candesartan und Sitagliptin) gleichzeitig betrachten kann. Die Karte passt sich der gefilterten Tabelle . Klickt man mit der Maus der Karte auf eine bestimmte Messstelle, erhält man einen Überblick über die Metadaten der Messstelle und kann über das Symbol recht der Zeile „station” einen Filter für diese Messstelle setzen. Die Angaben der Tabelle beziehen dann nur noch auf die dieser Messstelle erhobenen Daten. Fährt man mit der Maus über den Substanznamen der Tabelle, zeigt sich ein Auswahlmenü. Klickt man auf das „+“-Zeichen, kann man den Substanzfilter direkt einen anderen Quicklink der Gruppe „Analytical Data” übertragen, z. B. „Time series water”. Es öffnet sich ein neuer Tab.","code":""},{"path":"http://r.bafg.de/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"analytical-data-time-series-water","dir":"Articles","previous_headings":"Überblick und erste Möglichkeiten","what":"Analytical Data: Time series water","title":"Kurzanleitung zur ersten Nutzung","text":"Unter “Time series water samples” sind nur die Messstationen hinterlegt, für die zeitlich aufgelöste Proben vorliegen (Rhein und Elbe). Geht man direkt über die Startseite hierhin, kann man über das Dropdown Menü Filterungen vornehmen. Hat man bereits, wie 2.2 beschrieben, Filterungen vorgenommen, werden hier direkt die entsprechenden Zeitreihen angezeigt. Auch hier kann man mit einem Klick auf die Messstelle der Karte oder durch die Auswahl im Dropdown Menü “Station” die angezeigten Daten auf eine Messstelle eingrenzen. Im Beispiel waren drei Substanzen ausgewählt. Für diese werden den Diagrammen die Zeitreihen einmal normiert auf einen (oben) und nicht normiert (unten) dargestellt. Ist eine Substanz sowohl im positiven als auch im negativen Modus ionisierbar und messbar, werden beide Datensätze angezeigt. Fährt man mit dem Mauszeigen den Legenden der Zeitreihen die einzelnen Datenreihen ab, werden alle anderen ausgegraut. Mit Klick auf eine Datenreihe, wird nur noch diese angezeigt (kann durch einen weiteren Klick rückgängig gemacht werden).","code":""},{"path":"http://r.bafg.de/articles/Kurzanleitung-zur-ersten-Nutzung.html","id":"analytical-data-time-series-spm","dir":"Articles","previous_headings":"Überblick und erste Möglichkeiten","what":"Analytical Data: Time series SPM","title":"Kurzanleitung zur ersten Nutzung","text":"Dieser Bereich ist ähnlich aufgebaut wie „Time series water” und kann auf die gleiche Weise verwendet werden.","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Library screening","text":"Measurement files processed using library screening algorithm known DBAS. parameters processing, well location necessary input files, stored msrawfiles index. output stored dbas index. See naming conventions indices.","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"reprocessing-all-datafiles-in-msrawfiles-index","dir":"Articles","previous_headings":"","what":"Reprocessing all datafiles in msrawfiles index","title":"Library screening","text":"additions made spectral library datafiles must reprocessed. making necessary changes msrawfiles table, processing can started various dbaScreening* functions depending processing take place (locally, server etc.). example, dbaScreeningSelectedBatchesSlurm() used begin processing using SLURM workload manager.","code":""},{"path":[]},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"connecting-to-elasticsearch-cluster","dir":"Articles","previous_headings":"Overview of processing algorithm","what":"Connecting to ElasticSearch cluster","title":"Library screening","text":"Connection within BfG achieved R using connectNtsportal(). use stored credentials build connection (PythonDbComm interface).","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"general-workflow","dir":"Articles","previous_headings":"Overview of processing algorithm","what":"General workflow","title":"Library screening","text":"HRMS measurement files stored mzXML files filesystem, directories representing batches (measurement sequences). files previously converted vendor specific formats (.raw, .wiff, etc.) using Proteowizard’s msconvert-tool. msrawfiles table used manage metadata. measurement file record table contains information file’s path, sampling acquisition information processing parameters. msrawfile-records used control processing workflow. workflow complete, data saved JSON file format needed Elasticsearch ingest (importing data Elasticsearch). ingest done separate step.","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"process-launching","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Process launching","title":"Library screening","text":"user runs one several dbaScreening* functions start processing either locally via SLURM. dbaScreeningSelectedBatchesSlurm() (commonly used) specific directories (.e. batches) containing measurement files passed either listing directly giving root directory. Alternatively, user can process “new” batches using dbaScreeningUnprocessedBatchesSlurm() (Section Collecting msrawfile records).","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"processing-using-the-workflow-manager-slurm","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow > Process launching","what":"Processing using the workflow manager SLURM","title":"Library screening","text":"run screening via SLURM, first necessary job files created. user starts processing submitting job file (.sbatch) workload manager.","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"sec-collectingMsrawfileRecords","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Collecting msrawfile records","title":"Library screening","text":"dbaScreeningUnprocessedBatchesSlurm(), new batches selected looking dbas indices comparing files found (identified path field) files found msrawfiles. batches msrawfiles yet found dbas index selected processing. msrawfiles records loaded checks performed scanning process begins. Output list batches ntsportal::msrawfilesRecords.","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"file-wise-scanning","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"File-wise scanning","title":"Library screening","text":"measurement files scanned compounds spectral library results cleaned. result one dbasResult object batch (list data.frames containing peak information whole batch). dbasResult class","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"conversion-to-featurerecord","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Conversion to featureRecord","title":"Library screening","text":"results scanning (dbasResult) converted list format later import NTSportal (featureRecord). Additional compound information taken spectral library measurement file metadata taken msrawfiles added record. MS1, MS2 spectra EIC peak added available (peaks dbasResult$peakList data available).","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"writing-rds-for-database-import","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Writing RDS for database import","title":"Library screening","text":"list featureRecord objects one batch saved RDS file (using default gzip compression).","code":""},{"path":"http://r.bafg.de/articles/Library-screening.html","id":"database-import-ingest","dir":"Articles","previous_headings":"Overview of processing algorithm > General workflow","what":"Database import (ingest)","title":"Library screening","text":"ingesting documents, user must ensure enrich policies ingest pipelines date. done updateEnrichPolicies(), synchronize Elasticsearch current enrich policies ingest pipelines needed ntsportal. RDS files imported NTSPortal ingest(), calls Elasticsearch bulk ingest API via Python. user runs ingest() separately processing complete. ingest includes pipeline (ingest-feature) enriches document sample metadata found msrawfiles. fields sampling location sampling time, loc start fields, respectively.","code":""},{"path":"http://r.bafg.de/articles/Measurement-file-naming-conventions.html","id":"bfg-measurement-file-naming","dir":"Articles","previous_headings":"","what":"BfG measurement file naming","title":"Measurement file naming conventions","text":"Filenames always use lowercase letters (-z) Windows ignores capitalization Linux . Replicates named extrepX injrepX extraction injection replicates, respectively. X number 1-9. Parameters insert indicated <...> text fixed must copied exactly. Optional parameters given additionally square brackets [...]","code":""},{"path":"http://r.bafg.de/articles/Measurement-file-naming-conventions.html","id":"general-parameter-descriptions","dir":"Articles","previous_headings":"BfG measurement file naming","what":"General parameter descriptions","title":"Measurement file naming conventions","text":"<pol>: polarity (“pos” “neg”) <station>: see station naming conventions <composite type>: Jahresmischprobe “jmp”, Monatsmischprobe “mmp”, Tagesmischprobe “tmp”, Stichprobe “sp”","code":""},{"path":"http://r.bafg.de/articles/Measurement-file-naming-conventions.html","id":"frame-reference-samples","dir":"Articles","previous_headings":"BfG measurement file naming","what":"FRAME reference samples","title":"Measurement file naming conventions","text":"<Messdatum YYYY-MM-DD>_frame_mix_<instrument>_<concentration>ngl[_injrep<X>]_<pol> <instrument>: “wasser_tof” “sediment_tof”<concentration>: concentration ng/L<X>: replicate number (1-9) (one digit) Example: 2024-02-29_frame_mix_wasser_tof_1000ngl_injrep3_pos.wiff","code":""},{"path":"http://r.bafg.de/articles/Measurement-file-naming-conventions.html","id":"ase-blanks","dir":"Articles","previous_headings":"BfG measurement file naming","what":"ASE blanks","title":"Measurement file naming conventions","text":"<Messdatum YYYY-MM-DD>_ase_bw_<XX>_e<Extraktionsdatum YYYY-MM-DD>_<pol> <XX>: Continuous numbering within job (e.g. one year composite samples stations) (01-99, 2 digits) Example:2024-08-30_ase_bw_01_e2024-07-01_pos.wiff","code":""},{"path":"http://r.bafg.de/articles/Measurement-file-naming-conventions.html","id":"ase-reference-samples","dir":"Articles","previous_headings":"BfG measurement file naming","what":"ASE reference samples","title":"Measurement file naming conventions","text":"<Messdatum YYYY-MM-DD>_ase_ref_<XXX>_e<Extraktionsdatum YYYY-MM-DD>_<pol> <XXX>: Continuous numbering… forever (001-999, three digits) Example:2024-08-30_ase_ref_001_e2024-07-01_pos.wiff","code":""},{"path":"http://r.bafg.de/articles/Measurement-file-naming-conventions.html","id":"monthly-and-yearly-composite-spm-samples-umweltprobenbank","dir":"Articles","previous_headings":"BfG measurement file naming","what":"Monthly and yearly composite SPM samples (umweltprobenbank)","title":"Measurement file naming conventions","text":"<station>_<Probenamedatum YYYY / YYYY-MM>_<composite type>_extrep<X>_<pol> <X>: replicate number (1-9, one digit) Example:rhein_ko_l_2023_jmp_extrep1_pos.wiff","code":""},{"path":"http://r.bafg.de/articles/Measurement-file-naming-conventions.html","id":"daily-composite-samples-water-matrix-bfg-stations","dir":"Articles","previous_headings":"BfG measurement file naming","what":"Daily composite samples water matrix (BfG stations)","title":"Measurement file naming conventions","text":"<station>_<Probenamedatum YYYY-MM-DD>_<composite type>[_injrep<X>]_<pol> <X>: replicate number (1-9) (one digit) Example:rhein_ko_l_2025-01-13_tmp_pos.wiff","code":""},{"path":"http://r.bafg.de/articles/Measurement-file-naming-conventions.html","id":"old-naming","dir":"Articles","previous_headings":"BfG measurement file naming","what":"Old naming","title":"Measurement file naming conventions","text":"Old station naming monatsmischproben Old naming system annual composite samples: ‘JJ’ refers two digit year, ‘X’ replicate number.","code":""},{"path":"http://r.bafg.de/articles/Modify-documents-using-API.html","id":"overwrite-a-value","dir":"Articles","previous_headings":"","what":"Overwrite a value","title":"Modifying documents using the Update By Query API","text":"IMPORTANT: Always run query first using GET <INDEX>/_search check results correct. copy query POST statement. careful copying code previous command change necessary values. Use update query API. Example:","code":"GET <INDEX>/_search {   \"query\": {     \"term\": {       \"station\": \"NAME1\"     }   } }  POST <INDEX>/_update_by_query {   \"query\": {     \"term\": {       \"station\": \"NAME1\"     }   },   \"script\" : \"ctx._source.station = 'NAME2'\" }"},{"path":"http://r.bafg.de/articles/Modify-documents-using-API.html","id":"overwrite-a-field-via-a-painless-script","dir":"Articles","previous_headings":"Overwrite a value","what":"Overwrite a field via a Painless script","title":"Modifying documents using the Update By Query API","text":"case want change station name adding prefix part existing station name. Note: third debug statement active code . + used string concatination. declare string must use String. split string character use string method splitOnToken. produces array.","code":"GET <INDEX>/_search {   \"query\" : {     \"regexp\": {       \"station\": \"ow_.*\"     }   },   \"aggs\": {     \"stations\": {       \"terms\": {         \"field\": \"station\",         \"size\": 11       }     }   },   \"size\": 0 }  POST <INDEX>/_update_by_query {   \"query\" : {     \"regexp\": {       \"station\": \"OW_\\\\d+\"     }   },   \"script\": {     \"source\": \"\"\"       // Debug.explain(params.new_prefix);       // Debug.explain(params.newPrefix + ctx._source.station.splitOnToken('_')[1]);       String newName = params.newPrefix + ctx._source.station.splitOnToken('_')[1];       Debug.explain(newName)       ctx._source.station = newName;       \"\"\",     \"params\": {       \"newPrefix\": \"ow_hess_ried_\"     }   } }"},{"path":"http://r.bafg.de/articles/Modify-documents-using-API.html","id":"create-or-append-to-array","dir":"Articles","previous_headings":"","what":"Create or append to array","title":"Modifying documents using the Update By Query API","text":"entry treated array (multiple entries), tag comment fields, need explicitly saved arrays. following script test entry exists create array. already entry (array ) make array append new value. field values change given params field script.","code":"POST <INDEX>/_update_by_query {   \"query\": {     <query code>   },   \"script\": {     \"params\": {       \"fieldToChange\": \"comment\",       \"newValue\": \"Instrument name: Sediment TOF\"     },     \"source\": \"\"\"       if (ctx._source[params.fieldToChange] == null) {         ctx._source[params.fieldToChange] = [params.newValue];       } else if (!(ctx._source[params.fieldToChange] instanceof List)) {         ctx._source[params.fieldToChange] = [ctx._source[params.fieldToChange]];         ctx._source[params.fieldToChange].add(params.newValue);       } else {         ctx._source[params.fieldToChange].add(params.newValue)       }       \"\"\"   } }"},{"path":"http://r.bafg.de/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"simple-search-example-with-the-term-query","dir":"Articles","previous_headings":"","what":"Simple search example with the term query","title":"Using the Elasticsearch Search API with Query DSL for retrieving documents","text":"simple example shown show structure query. example retrieves detections station “mosel_ko_r”.","code":""},{"path":"http://r.bafg.de/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"using-the-kibana-dev-tools-console","dir":"Articles","previous_headings":"Simple search example with the term query","what":"Using the Kibana Dev Tools console","title":"Using the Elasticsearch Search API with Query DSL for retrieving documents","text":"","code":"GET ntsp25.2_dbas*/_search {   \"query\": {     \"term\": {       \"station\": \"mosel_139\"     }   } }"},{"path":"http://r.bafg.de/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"using-curl","dir":"Articles","previous_headings":"Simple search example with the term query","what":"using curl","title":"Using the Elasticsearch Search API with Query DSL for retrieving documents","text":"","code":"curl -X GET \"https://<hostname>:<port>/ntsp25.2_dbas*/_search\" \\      -H 'Content-Type: application/json' \\      -H 'Authorization: ApiKey <sectret>' \\      -d' {   \"query\": {     \"term\": {       \"station\": \"mosel_139\"     }   } }'"},{"path":"http://r.bafg.de/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"using-ntsportal","dir":"Articles","previous_headings":"Simple search example with the term query","what":"Using ntsportal","title":"Using the Elasticsearch Search API with Query DSL for retrieving documents","text":"getTableAsTibble() implements Python elasticsearch-dsl package back-end.","code":"library(ntsportal) connectNtsportal() dbComm <- getDbComm() tb <- getTableAsTibble(   dbComm,    tableName = \"ntsp25.2_dbas*\",    searchBlock = list(     query = list(       term = list(         station = \"mosel_139\"       )     )   ) )"},{"path":[]},{"path":"http://r.bafg.de/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"using-elasticsearch-package","dir":"Articles","previous_headings":"Simple search example with the term query > Using Python","what":"Using elasticsearch package","title":"Using the Elasticsearch Search API with Query DSL for retrieving documents","text":"","code":"from elasticsearch import Elasticsearch client = Elasticsearch(hosts=\"https://hosturl.mydomain.de\", api_key=\"<secret>\") response = client.search(   index=\"ntsp25.2_dbas*\",    body={     \"query\": {       \"term\": {         \"station\": \"mosel_139\"         }       }     } )"},{"path":"http://r.bafg.de/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"using-elasticsearch-dsl-package","dir":"Articles","previous_headings":"Simple search example with the term query > Using Python","what":"Using elasticsearch-dsl package","title":"Using the Elasticsearch Search API with Query DSL for retrieving documents","text":"recommended method programming Python basis getTable* functions ntsportal. Note: example uses elasticsearch 8.17.2 elasticsearch-dsl 8.17.1. newer versions, elasticsearch-dsl integrated elasticsearch.","code":"from elasticsearch import Elasticsearch from elasticsearch_dsl import Search client = Elasticsearch(hosts=\"https://hosturl.mydomain.de\", api_key=\"<secret>\") s = Search(using=client, index=\"ntsp25.2_dbas*\").update_from_dict(   {     \"query\":{       \"term\":{         \"station\": \"mosel_139\"       }     }   } ) for hit in s.iterate():   print(hit.to_dict())"},{"path":"http://r.bafg.de/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"combining-search-parameters-with-bool","dir":"Articles","previous_headings":"","what":"Combining search parameters with bool","title":"Using the Elasticsearch Search API with Query DSL for retrieving documents","text":"search query usually complex example . example search datafiles polarity negative, blanks, stations ulm wettin.","code":"GET ntsp_msrawfiles/_search {   \"query\": {     \"bool\": {       \"must\": [         {           \"term\": {             \"pol\": {               \"value\": \"neg\"             }           }         }       ],       \"must_not\": [         {           \"term\": {             \"blank\": {               \"value\": \"true\"             }           }         }       ],       \"should\": [         {           \"term\": {             \"station\": {               \"value\": \"donau_ul_m\"             }           }         },         {           \"term\": {             \"station\": {               \"value\": \"saale_wettin_m\"             }           }         }       ],        \"minimum_should_match\": 1     }   } }"},{"path":"http://r.bafg.de/articles/Searching-with-ElasticSearch-Query-DSL.html","id":"paginating-search-results-selecting-fields-and-converting-to-a-data-frame-in-r-","dir":"Articles","previous_headings":"Combining search parameters with bool","what":"Paginating search results, selecting fields and converting to a data.frame in R.","title":"Using the Elasticsearch Search API with Query DSL for retrieving documents","text":"example, retrieving documents measurement station “mosel_ko_r” (Moselle, Koblenz, right bank), select certain fields. Using Dev Tools console, make following request: response shows total number hits greater equal (gte) 10000 (max documents reached). Therefore, can retrieve documents one request must paginate search results. function ntsportal::esSearchPaged() works similarly elastic::Search paginate results. response list transformed data.frame. Note: esSearchPaged() deprecated favor getTableAsTibble().","code":"GET ntsp25.2_dbas*/_search {   \"query\": {     \"term\": {       \"station\": {         \"value\": \"mosel_ko_r\"       }     }   },   \"_source\": [\"name\", \"inchikey\", \"pol\", \"start\", \"duration\",                \"area\", \"area_is\", \"area_normalized\"] } connectNtsportal() res <- esSearchPaged(\"ntsp25.2_dbas*\", searchBody = list(query = list(term = list(station = \"mosel_ko_r\"))),     source = c(\"name\", \"inchikey\", \"pol\", \"start\", \"duration\", \"area\"), sort = \"mz\")   # Convert the returned list to a data.frame temp <- lapply(res$hits$hits, function(x) as.data.frame(x[[\"_source\"]])) df <- plyr::rbind.fill(temp)"},{"path":"http://r.bafg.de/articles/Station-naming.html","id":"general-conventions","dir":"Articles","previous_headings":"","what":"General conventions","title":"Station naming conventions","text":"stations named best possible convention <river>_<location>_<bank>. river name uses local spelling complete character set (ß etc.). enables easier wildcard searching, example rhein* find measurement stations Rhine river. location can either town, district, river-km (must km , e.g., donau_km50, . used decimals). Numbering stations along river accepted (either numbers letters, e.g., permitted: elbe_1, lahn_a. code used location, e.g. jo Jochenstein, code needs added table . bank indicates bank sample taken (left: l, right: r, m middle). Banks always named direction flow, canals see Teil II Binnenschiffahrtsverordnung. text lower-case without spaces, punctuation special characters (´, \", ,, etc.).","code":""},{"path":"http://r.bafg.de/articles/Station-naming.html","id":"table-of-station-codes","dir":"Articles","previous_headings":"","what":"Table of station codes","title":"Station naming conventions","text":"See also Gist Station descriptions: Schulze, T.; Ricking, M. (2005): Abschlussbericht: Entwicklung einer Verfahrensrichtlinie „Sedimente und Schwebstoffe“. Freie Universität Berlin, Umweltbundesamt, UBA, Berlin. Link","code":""},{"path":"http://r.bafg.de/articles/Structure-of-NTSPortal.html","id":"software-architecture","dir":"Articles","previous_headings":"","what":"Software architecture","title":"Structure of NTSPortal","text":"NTSPortal system made many components can grouped three sections: ‘measurement file processing’, ‘data management’ ‘visualization’. following dependency diagram gives overview main, high-level, software components.","code":""},{"path":"http://r.bafg.de/articles/Structure-of-NTSPortal.html","id":"hardware-architecture","dir":"Articles","previous_headings":"","what":"Hardware architecture","title":"Structure of NTSPortal","text":"hardware components used run NTSPortal can similarly categorized software. core component NTSPortal high-performance computing cluster (HPC) used measurement file processing. system consists 7 compute nodes 64 CPUs 503 GB memory. HPC controlled HPC control server. Measurement files stored network attached storage (NAS), synchronized fast, SSD-based storage (BeeGFS). data management component consists separate server (R-server) 3-node cluster running Elasticsearch (containerized). visualization component accomplished server hosting dashboards (Kibana). traffic Internet runs reverse proxy security reasons. servers virtualized run Rocky Linux 8.10 Elasticsearch cluster, R Kibana servers run HCI (hyper-converged infrastructure).","code":""},{"path":"http://r.bafg.de/articles/Structure-of-NTSPortal.html","id":"index-mappings-db-schema","dir":"Articles","previous_headings":"","what":"Index mappings (DB Schema)","title":"Structure of NTSPortal","text":"ElasticSearch uses indices store data. NTSPortal contains different index types, different structure. mapping code field descriptions different tables: dbas (results library screening data processing) msrawfiles (metadata processing parameters measurement files) analysis_dbas (summary statistics dbas) spectral_library (copy collective spectral library - CSL)","code":""},{"path":"http://r.bafg.de/articles/Structure-of-NTSPortal.html","id":"index-naming-conventions","dir":"Articles","previous_headings":"","what":"Index naming conventions","title":"Structure of NTSPortal","text":"indices named using convention:ntsp<version number>_index_<index type>_v<ingest time 'YYMMDDHHmmSS'>_<project institute> example: ntsp25.2_index_analysis_dbas_v240215101520_bfg, ntsp25.2_index_nts_v240316101520_lanuv defined codes project institute.","code":""},{"path":"http://r.bafg.de/articles/Structure-of-NTSPortal.html","id":"exceptions","dir":"Articles","previous_headings":"Index naming conventions","what":"Exceptions","title":"Structure of NTSPortal","text":"index types msrawfiles spectral_library one index alias, just called ntsp25.2_msrawfiles ntsp25.2_spectral_library. index type can number indices, particular project, institute subset data.","code":""},{"path":"http://r.bafg.de/articles/Structure-of-NTSPortal.html","id":"aliases","dir":"Articles","previous_headings":"","what":"Aliases","title":"Structure of NTSPortal","text":"ElasticSearch uses aliases make accessing index easier. names designed shorter change. point index. aliases following naming convention:ntsp<version number>_<index type>_<project institute> example: ntsp25.2_dbas_bfg alias point current version index. way, several versions index can maintained concurrently testing backup purposes.","code":""},{"path":"http://r.bafg.de/articles/Structure-of-NTSPortal.html","id":"data-views","dir":"Articles","previous_headings":"","what":"Data views","title":"Structure of NTSPortal","text":"Kibana uses data views allow granular data access rights. data view name pattern potentially matching one several indices (aliases). user role, role given access specific indices. dashboards Kibana built data views programmed users role determines indices visible dashboard. example data view : ntsp25.2_dbas*. data view access aliases ntsp25.2_dbas_bfg ntsp25.2_dbas_lanuv, example. user role ntsp_lanuv, access aliases therefore linked indices, see datasets viewing dashboard visual using data view. important alias names subset indices. ntsp_is_dbas alias correct ntsp_dbas_is incorrect. second alias also match data view ntsp_dbas* therefore internal standard data appear together results. following table shows examples naming conventions","code":""},{"path":"http://r.bafg.de/articles/using-ntsportal-front-end.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the NTSPortal front-end","text":"NTSPortal UI ntsportal.bafg.de built using Kibana platform (Documentation). allows interactive viewing data.","code":""},{"path":"http://r.bafg.de/articles/using-ntsportal-front-end.html","id":"registration-and-user-access","dir":"Articles","previous_headings":"Introduction","what":"Registration and user access","title":"Using the NTSPortal front-end","text":"Access ntsportal.bafg.de currently restricted IP whitelisting still development. static IP addresses permitted must white-listed BfG. Signing access currently restricted German government offices. Please contact BfG information send request access ntsportal@bafg.de.","code":""},{"path":"http://r.bafg.de/articles/using-ntsportal-front-end.html","id":"structure","dir":"Articles","previous_headings":"Introduction","what":"Structure","title":"Using the NTSPortal front-end","text":"homepage ntsportal.bafg.de series links left-hand side access different dashboards (pages different views data). homepage linked dashboards restricted annotated features, meaning non-target detections match Collective Spectral Library (CSL).","code":""},{"path":[]},{"path":"http://r.bafg.de/articles/using-ntsportal-front-end.html","id":"search-for-a-compound-in-the-database-and-view-the-spatial-distribution-and-time-series","dir":"Articles","previous_headings":"Example usage","what":"Search for a compound in the database and view the spatial distribution and time series","title":"Using the NTSPortal front-end","text":"homepage, following link “Search substances”, initially user see full dataset (user’s role access ). table left lists detected compounds map displays detections dots. drop-menus top screen allow user filter data compound several compounds interest using name identifiers, compound groups filtering m/z. selected, table map filtered compound(s). hovering name compound, “+” button appear, provides “drilldowns” – links dashboards view details. example, one can view time series selected compound sites time series data available.","code":""},{"path":"http://r.bafg.de/articles/using-ntsportal-front-end.html","id":"filter-context-in-kibana","dir":"Articles","previous_headings":"","what":"Filter context in Kibana","title":"Using the NTSPortal front-end","text":"dashboards views dataset available current user (defined roles). user assigned role (roles) specific data access rights. dashboards initially display large (albeit truncated) dataset user expected filter data interest, e.g., selecting specific compounds sampling locations. known filter context usually applies visualizations within dashboard. Kibana provides several different filtering methods: Within dashboards drop-menus provided important fields. primary filtering method. dashboards search box provide custom filters using relatively simple KQL syntax. requires knowledge field names structure database. left search box “+”-button custom filters can added graphically. right search box time selector, data can filtered time (sampling time, measurement time import time, depending dashboard).","code":""},{"path":"http://r.bafg.de/articles/using-ntsportal-front-end.html","id":"data-truncation","dir":"Articles","previous_headings":"","what":"Data truncation","title":"Using the NTSPortal front-end","text":"Depending visualization, data displayed user may automatically truncated minimize latency. much data truncated depends visualization. Data may also need summarized server sent browser. instance, data time series peak area compound daily measurements may large summarized weekly data points taking median intensity week. Truncating summarizing done ElasticSearch query time. Kibana receives truncated data displays . order see whole data interest, user expected narrow filter context.","code":""},{"path":"http://r.bafg.de/articles/using-ntsportal-front-end.html","id":"custom-queries-with-kibana-query-language","dir":"Articles","previous_headings":"","what":"Custom queries with Kibana Query Language","title":"Using the NTSPortal front-end","text":"KQL searchbox allows user set complex filters within dashboard. full reference KQL see elasticsearch documentation. basic form query field : value, field names values can read tables left. Examples: search compound: name: Carbamazepine Search two compounds: name: Valsartan name: \"Valsartan acid\" Wildcard search: station: rhein* Numeric range search: mz > 237.1 mz < 237.2 nested fields (see field mappings) queried field: {field : value }, example search compounds fragments 179 (lower intensity) 194 (dominant fragment) positive ionisation mode: ms2: { mz > 179 mz < 180 int > 0.2 } ms2: { mz > 194 mz < 195 int > 0.8 } pol: pos","code":""},{"path":"http://r.bafg.de/articles/using-ntsportal-front-end.html","id":"notes","dir":"Articles","previous_headings":"Custom queries with Kibana Query Language","what":"Notes","title":"Using the NTSPortal front-end","text":"custom filters, set, user must “Refresh” send query database retrieve new data. done automatically using drop-menus. plots allow user “toggle-hide” datapoints (e.g. clicking legend entry time series, selected series hidden). fetch new data database. original query truncated, remain .","code":""},{"path":"http://r.bafg.de/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kevin S. Jewell. Maintainer.           Federal Institute Hydrology (BfG) Koblenz, Germany Ole Lessmann. Author.           Federal Institute Hydrology (BfG) Koblenz, Germany Jonas Skottnik. Contributor.           Federal Institute Hydrology (BfG) Koblenz, Germany Franziska Prodöhl. Contributor.           Federal Institute Hydrology (BfG) Koblenz, Germany Nina Hermes. Contributor.           Federal Institute Hydrology (BfG) Koblenz, Germany Arne Wick. Reviewer.           Federal Institute Hydrology (BfG) Koblenz, Germany","code":""},{"path":"http://r.bafg.de/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jewell, K., Thron, F., Schlüsener, M., Kramer, K., Scharrenbach, T., Fettig, ., Koschorreck, J., Schulte, C., Ternes, T., & Wick, . (2021). Ein Datenbankmodell für aggregierte Non-Target-Screening-Ergebnisse. Vom Wasser, 119(3), 94-96. https://doi.org/10.1002/vomw.202100020","code":"@Article{,   title = {Ein Datenbankmodell für aggregierte Non-Target-Screening-Ergebnisse},   journal = {Vom Wasser},   volume = {119},   number = {3},   pages = {94-96},   year = {2021},   author = {{Jewell} and Kevin S. and {Thron} and {Franziska} and {Schlüsener} and {Michael} and {Kramer} and {K.} and {Scharrenbach} and {T.} and {Fettig} and {I.} and {Koschorreck} and {J.} and {Schulte} and {C.} and {Ternes} and Thomas A. and {Wick} and {Arne}}, }"},{"path":"http://r.bafg.de/index.html","id":"ntsportal","dir":"","previous_headings":"","what":"ntsportal - Functions for building and managing the NTSPortal database","title":"ntsportal - Functions for building and managing the NTSPortal database","text":"goal R-package ntsportal provide backend NTSPortal database online dashboards non-target-screening data (based LC-HRMS measurements) surface waters. NTSPortal designed process measurement files make processed data available via API online dashboards. dashboards allow searching, data analysis visualization. detailed statistical analysis, API can used accessing data Python R scripts. system currently uses Elasticsearch storing searching data. R-package used processing managing data search engine. functions data processing use ntsworkflow. information structure internal design NTSPortal please refer documentation. Access internally managed NTSPortal database available upon request. Please contact Federal Institute Hydrology ntsportal@bafg.de. repository includes back-end code publication purposes include environmental data.","code":""},{"path":"http://r.bafg.de/index.html","id":"project-funding","dir":"","previous_headings":"","what":"Project Funding","title":"ntsportal - Functions for building and managing the NTSPortal database","text":"project initiated research funding grant Federal Environment Agency (UBA, “Online Portal: Non-Target-Screening für die Umweltüberwachung der Zukunft” REFOPLAN 3720222010) continued funding provided research grant REFOPLAN 3723222020 (“Weiterentwicklung des Online Portals für die Umweltbeobactung der Zukunft”). Additional funding provided Federal Ministry Transport (BMV) Federal Ministry Environment (BMU).","code":""},{"path":"http://r.bafg.de/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"ntsportal - Functions for building and managing the NTSPortal database","text":"Copyright 2025 Bundesanstalt für Gewässerkunde (Federal Institute Hydrology) ntsportal free software: can redistribute /modify terms GNU General Public License published Free Software Foundation, either version 3 License, (option) later version. ntsportal distributed hope useful, WITHOUT WARRANTY; without even implied warranty MERCHANTABILITY FITNESS PARTICULAR PURPOSE. See GNU General Public License details. received copy GNU General Public License along ntsportal. , see https://www.gnu.org/licenses/. use package derivative thereof, please cite work, see citation(\"ntsportal\").","code":""},{"path":"http://r.bafg.de/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"ntsportal - Functions for building and managing the NTSPortal database","text":"NTSPortal conglomerate many systems (see Structure NTSPortal). guide describes installation R-package ntsportal (back-end processing management tool).","code":""},{"path":"http://r.bafg.de/index.html","id":"installation-via-github","dir":"","previous_headings":"Installation","what":"Installation via Github","title":"ntsportal - Functions for building and managing the NTSPortal database","text":"Create Github PAT Add , following line, ~/.Rprofile Restart R session 4a) Confirm Python virtual environment available errors, check reticulate installed virtual environment activated (RStudio Project Global options). virtual environment available, use reticulate::virtualenv_create(). Install ntsportal Install Python packages already created, command create “r-reticulate” Python virtual environment install packages. Setup connection Elasticsearch","code":"Sys.setenv(GITHUB_PAT = \"<...>\") reticulate::virtualenv_exists() remotes::install_github(\"bafg-bund/ntsportal\") reticulate::virtualenv_install(requirements = fs::path_package(\"ntsportal\", \"pythonElasticComm\", \"requirements.txt\")) library(ntsportal) options(ntsportal.elasticsearchHostUrl = \"https://my.elastic.cluster\") connectNtsportal()  # first time: enter username and password ping(getDbComm())"},{"path":"http://r.bafg.de/reference/addRawfiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Add new records for MS measurement files to msrawfiles index — addRawfiles","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"Add new records MS measurement files msrawfiles index","code":""},{"path":"http://r.bafg.de/reference/addRawfiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"","code":"addRawfiles(   rfIndex,   templateId,   newPaths,   newStart = \"filename\",   newStation = \"same_as_template\",   dirMeasurmentFiles = \"/srv/cifs-mounts/g2/G/G2/HRMS/Messdaten/\",   promptBeforeIngest = TRUE,   saveDirectory = getwd(),   newStationList = list(station = \"example_new_station\", loc = list(lat = 1.23456, lon =     1.23456), river = \"example_new_river\", gkz = 99999, km = 99999) )"},{"path":"http://r.bafg.de/reference/addRawfiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"templateId ES-ID existing msrawfiles-record use template newPaths Character vector full paths new rawfiles added, must mzXML files. newStart Either \"filename\" (default), meaning extract start time filename provide start date 8 digit number \"YYYYMMDD\" newStation Either \"same_as_template\" (default), copy value template document, \"filename\", meaning extract station loc values code filename (compare docs msrawfiles index) \"newStationList\" add new station. See details. dirMeasurmentFiles Root directory original measurement files located. function look original (vendor) files directory . Must end \"/\". promptBeforeIngest user asked verify submission? (Default: TRUE). file called \"add-rawfiles-check.json\" created saveDirectory user can check make changes . See details \"making manual changes\". saveDirectory Location save temporary json file checking making manual changes. (defaults current working dir) newStationList List fields \"station\" \"loc\" optionally \"river\", \"gkz\" \"km\" add new station. see details rfindex index name rawfiles index","code":""},{"path":"http://r.bafg.de/reference/addRawfiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"Returns vector new ES-IDs generated imported documents","code":""},{"path":"http://r.bafg.de/reference/addRawfiles.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"Adding location information (`station` `loc` fields)   newStation can either \"same_as_template\", \"filename\" \"newStationList\". Using \"same_as_template\" means station location information copied template Using \"filename\" means use `dbas_station_regex` field index get station information   another record index. function use regex extract station code filename   search msrawfiles index records station code. unambiguous location found,   gather available location information use new record entry. option useful batch   added contains one station. Using \"newStationList\" means new fixed station name location passed (use list argument   \"newStationList\" fields \"station\" \"loc\" optionally \"river\", \"gkz\" \"km\") \"loc\" geopoint   fields \"lat\" \"lon\". Station river names lowercase spaces special   characters. station name use convention <river_town_position> position l, r m left,   right, middle. obvious town km known, use convention <river>_<km> station   name. neither town km known, use convention <river>_<description> description   indication location. Adding sample time information (`start` field) Using \"filename\" means sample time extracted filename. field `dbas_date_regex` used   find date sample file name. works conjunction `dbas_date_format`. `dbas_date_regex`   extracts text, `dbas_date_format` tells R interpret text. example, file name   `RH_pos_20170101.mzXML` uses date_regex `\"([20]*\\d6)\"` date_format `\"ymd\"`. `dbas_date_regex` uses   tidyverse regular expression syntax `stringr::str_match` function extract text referring   date. brackets indicate text extract can surrounded anchors. also possible   multiple brackets, text multiple brackets combined parsing. example file   `UEBMS_2024_002_Main_Kahl_Jan_pos_DDA.mzXML` can parsed date_regex `_(20\\d2)_.*_(\\w3)_pos`   date_format `ym`. `dbas_date_format` may one `\"ymd\"`, `\"dmy\"`, `\"ym\"` year-month `\"yy\"` just year. date   parsing done `lubridate`. Making manual changes Manual changes can made json one document added (minimize errors). Select \"c\"   promt (changes json saved). File storage locations location mzXML files stored given argument `newPaths`.`saveDirectory` json   file written . `dirMeasurmentFiles` used look original (non-converted) vendor files (e.g.,   wiff files) read measurement time (copied mzXML file using converters). Depending   number files uploaded, function can slow function look large   directory. improve performance, can tell function look smaller directory. files found   function add creation time mzXML file.","code":""},{"path":"http://r.bafg.de/reference/addRawfiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add new records for MS measurement files to msrawfiles index — addRawfiles","text":"","code":"if (FALSE) { # \\dontrun{ library(ntsportal) connectNtsportal() rfindex <- \"ntsp_msrawfiles\" paths <- list.files(\"/beegfs/nts/ntsportal/msrawfiles/ulm/schwebstoff/dou_pos/\", \"^Ulm.*mzXML$\", full.names = TRUE) templateId <- findTemplateId(rfindex, blank = FALSE, pol = \"pos\", station = \"donau_ul_m\", matrix = \"spm\") addRawfiles(rfindex = rfindex, templateId = templateId, newPaths = paths) checkMsrawfiles()  # Files in batch have different sample location addRawfiles(rfindex, \"eIRBnYkBcjCrX8D7v4H5\", newFiles[4:17], newStation = \"filename\",  dirMeasurmentFiles = \"~/messdaten/sachsen/\")   # Addition of a new station addRawfiles(   rfindex, \"eIRBnYkBcjCrX8D7v4H5\", newFiles[15],    newStation = \"newStationList\",   newStationList = list(     station = \"pleisse_9\",     loc = list(lat = 51.251489, lon = 12.383758),     river = \"pleisse\",     km = 9,     gkz = 5666   ) )  } # }"},{"path":"http://r.bafg.de/reference/addValueToArray.html","id":null,"dir":"Reference","previous_headings":"","what":"Add value to an array field — addValueToArray","title":"Add value to an array field — addValueToArray","text":"Add value array field","code":""},{"path":"http://r.bafg.de/reference/addValueToArray.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add value to an array field — addValueToArray","text":"","code":"addValueToArray(dbComm, tableName, field, value, searchBlock = list())"},{"path":"http://r.bafg.de/reference/addValueToArray.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add value to an array field — addValueToArray","text":"dbComm DbComm connection object tableName Name table database, wildcards permitted field table column (field) name see mappings value value set add searchBlock list coercible json Elasticsearch Search API (Query DSL)","code":""},{"path":[]},{"path":"http://r.bafg.de/reference/changeAliasAddress.html","id":null,"dir":"Reference","previous_headings":"","what":"Change alias of an index to a new index. — changeAliasAddress","title":"Change alias of an index to a new index. — changeAliasAddress","text":"delete previous alias","code":""},{"path":"http://r.bafg.de/reference/changeAliasAddress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change alias of an index to a new index. — changeAliasAddress","text":"","code":"changeAliasAddress(indexName, aliasName, closeAfter = FALSE)"},{"path":"http://r.bafg.de/reference/changeAliasAddress.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change alias of an index to a new index. — changeAliasAddress","text":"indexName Name index aliasName Name alias closeAfter logical, previous index, alias linked prior change, closed?","code":""},{"path":"http://r.bafg.de/reference/changeAliasAddress.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change alias of an index to a new index. — changeAliasAddress","text":"Passes response ES (acknowledged field, TRUE FALSE), invisibly","code":""},{"path":"http://r.bafg.de/reference/changeMsrawfileFilename.html","id":null,"dir":"Reference","previous_headings":"","what":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","title":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","text":"Used change filename measurement file simultaneously change `path` field `msrawfiles`.","code":""},{"path":"http://r.bafg.de/reference/changeMsrawfileFilename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","text":"","code":"changeMsrawfileFilename(rfIndex, oldPath, newPath)"},{"path":"http://r.bafg.de/reference/changeMsrawfileFilename.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change filename in the msrawfiles-db and on the filesystem — changeMsrawfileFilename","text":"rfIndex index name msrawfiles table oldPath Current path msrawfiles table newPath New path","code":""},{"path":"http://r.bafg.de/reference/changeMsrawfilePath.html","id":null,"dir":"Reference","previous_headings":"","what":"Change the path of one document in msrawfiles — changeMsrawfilePath","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"secure method changing \"path\" field entry msrawfiles. filename changed must remain . check files making change.","code":""},{"path":"http://r.bafg.de/reference/changeMsrawfilePath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"","code":"changeMsrawfilePath(rfIndex, oldPath, newPath, checkType = \"md5\")"},{"path":"http://r.bafg.de/reference/changeMsrawfilePath.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"rfIndex index name msrawfiles table oldPath Current path msrawfiles table newPath New path checkType Method check files , either \"md5\" (default) \"filesize\"","code":""},{"path":"http://r.bafg.de/reference/changeMsrawfilePath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"TRUE change successful (invisibly)","code":""},{"path":"http://r.bafg.de/reference/changeMsrawfilePath.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"files must exist making change. function takes time compares md5-checksums two files. large numbers files use filesize check.","code":""},{"path":"http://r.bafg.de/reference/changeMsrawfilePath.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change the path of one document in msrawfiles — changeMsrawfilePath","text":"","code":"if (FALSE) { # \\dontrun{ library(ntsportal) connectNtsportal()  ind <- \"ntsp_msrawfiles\" res <- esSearchPaged(ind, sort = \"path\", searchBody = list(query = list(regexp = list(path = \"/srv.*\"))), source = \"path\")$hits$hits partToRemove <- \"/srv/cifs-mounts/g2/G/G2/HRMS/Messdaten/\" paths <- sapply(res, function(x) x[[\"_source\"]]$path) oldPaths <- data.frame(oldPath = paths, relPath = sub(partToRemove, \"\", paths)) relPaths <- list.files(\"/beegfs/nts/ntsportal/msrawfiles\", recursive = T) newPaths <- data.frame(   newPath = paste0(\"/beegfs/nts/ntsportal/msrawfiles/\", relPaths),   relPath = relPaths )  oldAndNewPaths <- merge(oldPaths, newPaths, all.x = T, by = \"relPath\")  for (i in 1:nrow(oldAndNewPaths)) {   changeMsrawfilePath(ind, oldAndNewPaths$oldPath[i], oldAndNewPaths$newPath[i], checkType = \"filesize\")   } } # }"},{"path":"http://r.bafg.de/reference/checkMsrawfiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Check `msrawfiles` for validity — checkMsrawfiles","title":"Check `msrawfiles` for validity — checkMsrawfiles","text":"Checks `msrawfiles` table according current validation routine.","code":""},{"path":"http://r.bafg.de/reference/checkMsrawfiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check `msrawfiles` for validity — checkMsrawfiles","text":"","code":"checkMsrawfiles(indexName = \"ntsp25.2_msrawfiles\")"},{"path":"http://r.bafg.de/reference/checkMsrawfiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check `msrawfiles` for validity — checkMsrawfiles","text":"indexName default: ntsp_msrawfiles","code":""},{"path":"http://r.bafg.de/reference/checkMsrawfiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check `msrawfiles` for validity — checkMsrawfiles","text":"TRUE checks passed","code":""},{"path":"http://r.bafg.de/reference/checkPngAvailability.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that all structural formula PNGs have been created — checkPngAvailability","title":"Check that all structural formula PNGs have been created — checkPngAvailability","text":"Checks PNGs structural formulae consistent compounds spectral library. compares InChI-Keys library filenames prints inconsistencies console.","code":""},{"path":"http://r.bafg.de/reference/checkPngAvailability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that all structural formula PNGs have been created — checkPngAvailability","text":"","code":"checkPngAvailability(databasePath, targetDir)"},{"path":"http://r.bafg.de/reference/checkPngAvailability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that all structural formula PNGs have been created — checkPngAvailability","text":"databasePath Path spectral library (CSL, SQLite format) targetDir Path PNGs saved","code":""},{"path":"http://r.bafg.de/reference/checkPngSyncronization.html","id":null,"dir":"Reference","previous_headings":"","what":"Check synchronization with the picture server — checkPngSyncronization","title":"Check synchronization with the picture server — checkPngSyncronization","text":"Checks PNG file picture server disk identical.","code":""},{"path":"http://r.bafg.de/reference/checkPngSyncronization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check synchronization with the picture server — checkPngSyncronization","text":"","code":"checkPngSyncronization(fileUrl, filePathHd)"},{"path":"http://r.bafg.de/reference/checkPngSyncronization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check synchronization with the picture server — checkPngSyncronization","text":"fileUrl URL file picture server filePathHd Path file disk","code":""},{"path":"http://r.bafg.de/reference/connectNtsportal.html","id":null,"dir":"Reference","previous_headings":"","what":"Set ElasticSearch credentials and create ElasticSearch connection object — connectNtsportal","title":"Set ElasticSearch credentials and create ElasticSearch connection object — connectNtsportal","text":"NTSPortal credentials used build DbComm interface database. credentials available pop-ask user input (interactive use). Uses `keyring` package store retrieve credentials. default `keyring` backend used. working Linux console, 'file' backend, windows, 'wincred'. backend can set manually `Sys.setenv(\"R_KEYRING_BACKEND\" = \"file\")`.","code":""},{"path":"http://r.bafg.de/reference/connectNtsportal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set ElasticSearch credentials and create ElasticSearch connection object — connectNtsportal","text":"","code":"connectNtsportal()"},{"path":"http://r.bafg.de/reference/connectNtsportal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set ElasticSearch credentials and create ElasticSearch connection object — connectNtsportal","text":"additionally create `escon` connection object global environment use functions (deprecated, use DbComm interface)","code":""},{"path":"http://r.bafg.de/reference/convertToRecord.dbasResult.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a dbasResult to a list of featureRecords — convertToRecord.dbasResult","title":"Convert a dbasResult to a list of featureRecords — convertToRecord.dbasResult","text":"Convert dbasResult list featureRecords","code":""},{"path":"http://r.bafg.de/reference/convertToRecord.dbasResult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a dbasResult to a list of featureRecords — convertToRecord.dbasResult","text":"","code":"# S3 method for class 'dbasResult' convertToRecord(scanResult, msrawfileRecords)"},{"path":"http://r.bafg.de/reference/convertToRecord.dbasResult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a dbasResult to a list of featureRecords — convertToRecord.dbasResult","text":"","code":"if (FALSE) { # \\dontrun{ dbComm <- getDbComm() recs <- getTableAsRecords(   dbComm,    \"ntsp25.1_msrawfiles\",    searchBlock = list(query = list(regexp = list(filename = \"Des_.._.._pos.mzXML\"))),    newMsrawfilesRecord ) recsBlanks <- getTableAsRecords(   dbComm,    \"ntsp25.1_msrawfiles\",    searchBlock = list(query = list(regexp = list(path = \".*mud_pos/BW.*\"))),    newMsrawfilesRecord ) res <- scanBatchDbas(c(recs, recsBlanks), \"Methyltriphenylphosphonium\") featureRecs <- convertToRecord(res, c(recs, recsBlanks)) } # }"},{"path":"http://r.bafg.de/reference/convertToRecord.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a `dbasResult` to a `list` of `featureRecord`s — convertToRecord.dbasResult","title":"Convert a `dbasResult` to a `list` of `featureRecord`s — convertToRecord.dbasResult","text":"results DBAS file scanning (`scanResult`) converted NTSPortal `featureRecord` format. Compound sample metadata collected `msrawfileRecords` argument spectral library (CSL).","code":""},{"path":"http://r.bafg.de/reference/convertToRecord.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a `dbasResult` to a `list` of `featureRecord`s — convertToRecord.dbasResult","text":"","code":"# S3 method for class 'dbasResult' convertToRecord(scanResult, msrawfileRecords)"},{"path":"http://r.bafg.de/reference/convertToRecord.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a `dbasResult` to a `list` of `featureRecord`s — convertToRecord.dbasResult","text":"","code":"if (FALSE) { # \\dontrun{ dbComm <- getDbComm() recs <- getTableAsRecords(   dbComm,    \"ntsp25.2_msrawfiles\",    searchBlock = list(query = list(regexp = list(filename = \"Des_.._.._pos.mzXML\"))),    newMsrawfilesRecord ) recsBlanks <- getTableAsRecords(   dbComm,    \"ntsp25.2_msrawfiles\",    searchBlock = list(query = list(regexp = list(path = \".*mud_pos/BW.*\"))),    newMsrawfilesRecord ) res <- scanBatchDbas(c(recs, recsBlanks), \"Methyltriphenylphosphonium\") featureRecs <- convertToRecord(res, c(recs, recsBlanks)) } # }"},{"path":"http://r.bafg.de/reference/createAllStructures.html","id":null,"dir":"Reference","previous_headings":"","what":"Create images of structural formulae from the spectral library — createAllStructures","title":"Create images of structural formulae from the spectral library — createAllStructures","text":"Uses spectral library (CSL) obtain SMILES codes create PNG images structural formulae compounds.","code":""},{"path":"http://r.bafg.de/reference/createAllStructures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create images of structural formulae from the spectral library — createAllStructures","text":"","code":"createAllStructures(databasePath, targetDir)"},{"path":"http://r.bafg.de/reference/createAllStructures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create images of structural formulae from the spectral library — createAllStructures","text":"databasePath Path spectral library (CSL, SQLite format) targetDir Path PNGs saved","code":""},{"path":"http://r.bafg.de/reference/createBackupMsrawfiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a backup of an msrawfiles index — createBackupMsrawfiles","title":"Create a backup of an msrawfiles index — createBackupMsrawfiles","text":"create backup index current date name (`<msrawfilesName>_backup_<YYYYMMDD>`). overwrite index unless overwrite = TRUE. backup index immediately closed interfere.","code":""},{"path":"http://r.bafg.de/reference/createBackupMsrawfiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a backup of an msrawfiles index — createBackupMsrawfiles","text":"","code":"createBackupMsrawfiles(msrawfilesName, overwrite = FALSE)"},{"path":"http://r.bafg.de/reference/createBackupMsrawfiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a backup of an msrawfiles index — createBackupMsrawfiles","text":"msrawfilesName Name index back overwrite Logical, existing index overwritten (default false)","code":""},{"path":"http://r.bafg.de/reference/createBackupMsrawfiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a backup of an msrawfiles index — createBackupMsrawfiles","text":"Returns name new table","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningNewBatches.html","id":null,"dir":"Reference","previous_headings":"","what":"Process all measurement files which have not yet been processed by DBAS — dbaScreeningNewBatches","title":"Process all measurement files which have not yet been processed by DBAS — dbaScreeningNewBatches","text":"determine files yet processed, function collects directories `msrawfiles` looks `feature` indices see missing.","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningNewBatches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process all measurement files which have not yet been processed by DBAS — dbaScreeningNewBatches","text":"","code":"dbaScreeningNewBatches(msrawfileIndex, saveDirectory, numParallel = 1)"},{"path":"http://r.bafg.de/reference/dbaScreeningNewBatches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process all measurement files which have not yet been processed by DBAS — dbaScreeningNewBatches","text":"msrawfileIndex Name index processing information stored saveDirectory Location results saved numParallel local parallel processing via future","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningOneBatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Process one batch of measurement files by DBAS — dbaScreeningOneBatch","title":"Process one batch of measurement files by DBAS — dbaScreeningOneBatch","text":"Perform file scanning (DBAS), convert result NTSPortal `featureRecord` format save JSON.","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningOneBatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process one batch of measurement files by DBAS — dbaScreeningOneBatch","text":"","code":"dbaScreeningOneBatch(msrawfileRecords, saveDirectory)"},{"path":"http://r.bafg.de/reference/dbaScreeningOneBatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process one batch of measurement files by DBAS — dbaScreeningOneBatch","text":"saveDirectory Location results saved","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningSelectedBatches.html","id":null,"dir":"Reference","previous_headings":"","what":"DBAS process selected measurement files via batch directory — dbaScreeningSelectedBatches","title":"DBAS process selected measurement files via batch directory — dbaScreeningSelectedBatches","text":"Choose batches process selecting directory measurement files stored.","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningSelectedBatches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DBAS process selected measurement files via batch directory — dbaScreeningSelectedBatches","text":"","code":"dbaScreeningSelectedBatches(   msrawfileIndex,   batchDirs,   saveDirectory,   numParallel = 1 )"},{"path":"http://r.bafg.de/reference/dbaScreeningSelectedBatches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DBAS process selected measurement files via batch directory — dbaScreeningSelectedBatches","text":"msrawfileIndex Name index processing information stored batchDirs Directory measurement files (recursive, multiple permitted) saveDirectory Location results saved numParallel local parallel processing via future","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningSelectedBatchesSlurm.html","id":null,"dir":"Reference","previous_headings":"","what":"Process batches (DBAS) using SLURM by selecting directories — dbaScreeningSelectedBatchesSlurm","title":"Process batches (DBAS) using SLURM by selecting directories — dbaScreeningSelectedBatchesSlurm","text":"Choose batches process selecting directory measurement files stored. `dbaScreeningSelectedBatchesSlurm()` create necessary files submission job workflow manager SLURM.","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningSelectedBatchesSlurm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process batches (DBAS) using SLURM by selecting directories — dbaScreeningSelectedBatchesSlurm","text":"","code":"dbaScreeningSelectedBatchesSlurm(   msrawfileIndex,   batchDirs,   saveDirectory,   email )"},{"path":"http://r.bafg.de/reference/dbaScreeningSelectedBatchesSlurm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process batches (DBAS) using SLURM by selecting directories — dbaScreeningSelectedBatchesSlurm","text":"msrawfileIndex Name index processing information stored batchDirs Directory measurement files (recursive, multiple permitted) saveDirectory Location SLURM job files saved email Address SLURM notifications","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningSelectedBatchesSlurm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process batches (DBAS) using SLURM by selecting directories — dbaScreeningSelectedBatchesSlurm","text":"Three files created, records files process, organized batches (.RDS); R script SLURM needs run, SLURM job file (.sbatch). command needed start process given message (may need switch SLURM-enabled server).","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningSelectedBatchesSlurm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process batches (DBAS) using SLURM by selecting directories — dbaScreeningSelectedBatchesSlurm","text":"","code":"if (FALSE) { # \\dontrun{ userEmail <- \"example@bafg.de\" dirResults <- \"processingResults\" msrawfileIndexName <- \"ntsp25.2_msrawfiles\" library(ntsportal) connectNtsportal() file.remove(list.files(dirResults, f = T))  dbaScreeningSelectedBatchesSlurm(   msrawfileIndex = msrawfileIndexName,   batchDirs = \"/root/dir/all/msrawfiles\",   saveDirectory = dirResults,   email = userEmail ) } # }"},{"path":"http://r.bafg.de/reference/dbaScreeningUnprocessedBatchesSlurm.html","id":null,"dir":"Reference","previous_headings":"","what":"Process new batches (DBAS) using SLURM — dbaScreeningUnprocessedBatchesSlurm","title":"Process new batches (DBAS) using SLURM — dbaScreeningUnprocessedBatchesSlurm","text":"new batches selected, see `dbaScreeningNewBatches()`. function creates necessary file submit processing job SLURM workload manager. See `dbaScreeningSelectedBatchesSlurm()`","code":""},{"path":"http://r.bafg.de/reference/dbaScreeningUnprocessedBatchesSlurm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process new batches (DBAS) using SLURM — dbaScreeningUnprocessedBatchesSlurm","text":"","code":"dbaScreeningUnprocessedBatchesSlurm(msrawfileIndex, saveDirectory, email)"},{"path":"http://r.bafg.de/reference/dbaScreeningUnprocessedBatchesSlurm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process new batches (DBAS) using SLURM — dbaScreeningUnprocessedBatchesSlurm","text":"msrawfileIndex Name index processing information stored saveDirectory Location SLURM job files saved email Address SLURM notifications","code":""},{"path":"http://r.bafg.de/reference/DbComm-class.html","id":null,"dir":"Reference","previous_headings":"","what":"DbComm interface — DbComm-class","title":"DbComm interface — DbComm-class","text":"DbComm interface","code":""},{"path":"http://r.bafg.de/reference/deleteTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a table — deleteTable","title":"Delete a table — deleteTable","text":"named table removed database","code":""},{"path":"http://r.bafg.de/reference/deleteTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a table — deleteTable","text":"","code":"deleteTable(dbComm, tableName)  # S4 method for class 'PythonDbComm' deleteTable(dbComm, tableName)"},{"path":"http://r.bafg.de/reference/deleteTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a table — deleteTable","text":"dbComm DbComm connection object tableName Name table database, wildcards permitted","code":""},{"path":"http://r.bafg.de/reference/esSearchPaged.html","id":null,"dir":"Reference","previous_headings":"","what":"Get search results for more than 10000 docs by pagination. — esSearchPaged","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"deprecated favor `getTableAsRecords()`","code":""},{"path":"http://r.bafg.de/reference/esSearchPaged.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"","code":"esSearchPaged(   indexName,   searchBody = list(query = list(match_all = stats::setNames(list(), character(0)))),   sort,   totalSize = Inf,   ... )"},{"path":"http://r.bafg.de/reference/esSearchPaged.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"indexName Name ElasticSearch index (wildcard pattern) searchBody search body, default return docs sort Sort argument passed onto elastic::Search. Defines field results sorted (best unique docs avoid ties) currently can one field may '_id'. totalSize  ... arguments elastic::Search, asdf argument work.","code":""},{"path":"http://r.bafg.de/reference/esSearchPaged.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"ElasticSearch API response list","code":""},{"path":[]},{"path":"http://r.bafg.de/reference/esSearchPaged.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get search results for more than 10000 docs by pagination. — esSearchPaged","text":"","code":"if (FALSE) { # \\dontrun{ connectNtsportal() res <- esSearchPaged(\"ntsp25.2_dbas*\", searchBody = list(query = list(term = list(station = \"mosel_ko_r\"))),    source = c(\"name\", \"inchikey\", \"pol\", \"start\", \"duration\", \"area\"), sort = \"mz\")  # Convert the returned list to a data.frame temp <- lapply(res$hits$hits, function(x) as.data.frame(x[[\"_source\"]])) df <- plyr::rbind.fill(temp) } # }"},{"path":"http://r.bafg.de/reference/es_error_handler.html","id":null,"dir":"Reference","previous_headings":"","what":"Handle errors from ElasticSearch — es_error_handler","title":"Handle errors from ElasticSearch — es_error_handler","text":"Errors ElasticSearch returned package 'elastic' text. function take error condition take appropriate action.","code":""},{"path":"http://r.bafg.de/reference/es_error_handler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handle errors from ElasticSearch — es_error_handler","text":"","code":"es_error_handler(thisCnd)"},{"path":"http://r.bafg.de/reference/es_error_handler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handle errors from ElasticSearch — es_error_handler","text":"thisCnd Error condition thrown `tryCatch` context","code":""},{"path":"http://r.bafg.de/reference/es_error_handler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handle errors from ElasticSearch — es_error_handler","text":"return value","code":""},{"path":"http://r.bafg.de/reference/executeEnrichPolicy.html","id":null,"dir":"Reference","previous_headings":"","what":"Refresh an existing enrich policy — executeEnrichPolicy","title":"Refresh an existing enrich policy — executeEnrichPolicy","text":"Refresh existing enrich policy","code":""},{"path":"http://r.bafg.de/reference/executeEnrichPolicy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Refresh an existing enrich policy — executeEnrichPolicy","text":"","code":"executeEnrichPolicy(policyName, asBackgroundTask = TRUE)"},{"path":"http://r.bafg.de/reference/executeEnrichPolicy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Refresh an existing enrich policy — executeEnrichPolicy","text":"policyName Name policy asBackgroundTask Boolean, run background?","code":""},{"path":"http://r.bafg.de/reference/executeEnrichPolicy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Refresh an existing enrich policy — executeEnrichPolicy","text":"Task ID","code":""},{"path":"http://r.bafg.de/reference/findTemplateId.html","id":null,"dir":"Reference","previous_headings":"","what":"Get ID based on search parameters — findTemplateId","title":"Get ID based on search parameters — findTemplateId","text":"Get ID based search parameters","code":""},{"path":"http://r.bafg.de/reference/findTemplateId.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get ID based on search parameters — findTemplateId","text":"","code":"findTemplateId(   rfIndex,   blank = FALSE,   pol = \"pos\",   station = \"rhein_ko_l\",   matrix = \"spm\",   duration = 365 )"},{"path":"http://r.bafg.de/reference/findTemplateId.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get ID based on search parameters — findTemplateId","text":"rfIndex index name rawfiles index pol Either \"pos\" \"neg\", default \"pos\" station Station ID name matrix character default \"spm\" duration numeric, default 365 isBlank boolean default FALSE","code":""},{"path":"http://r.bafg.de/reference/findTemplateId.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get ID based on search parameters — findTemplateId","text":"ES-ID template record msrawfiles index","code":""},{"path":"http://r.bafg.de/reference/getDbComm.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a DbComm interface object — getDbComm","title":"Make a DbComm interface object — getDbComm","text":"Uses constructor given `ntsportal.dbComm` option","code":""},{"path":"http://r.bafg.de/reference/getDbComm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a DbComm interface object — getDbComm","text":"","code":"getDbComm()"},{"path":"http://r.bafg.de/reference/getNrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the number of rows in a table — getNrow","title":"Get the number of rows in a table — getNrow","text":"number rows (doc count) returned given table (wildcards allowed). `searchBlock` argument can used limit results search query.","code":""},{"path":"http://r.bafg.de/reference/getNrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the number of rows in a table — getNrow","text":"","code":"getNrow(dbComm, tableName, searchBlock = list())  # S4 method for class 'PythonDbComm' getNrow(dbComm, tableName, searchBlock = list())"},{"path":"http://r.bafg.de/reference/getNrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the number of rows in a table — getNrow","text":"dbComm DbComm connection object tableName Name table database, wildcards permitted searchBlock list coercible json Elasticsearch Search API (Query DSL)","code":""},{"path":"http://r.bafg.de/reference/getNrow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the number of rows in a table — getNrow","text":"integer","code":""},{"path":"http://r.bafg.de/reference/getTableAsRecords.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a table as a list of ntspRecords — getTableAsRecords","title":"Get a table as a list of ntspRecords — getTableAsRecords","text":"table retrieved `list` `ntspRecord`s subclass thereof. `recordConstructor` can used make subclass, e.g., make `msrawfilesRecord`s use `newMsrawfilesRecord`. default makes generic `ntspRecord`.","code":""},{"path":"http://r.bafg.de/reference/getTableAsRecords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a table as a list of ntspRecords — getTableAsRecords","text":"","code":"getTableAsRecords(   dbComm,   tableName,   searchBlock = list(),   fields = \"*\",   recordConstructor = newNtspRecord )"},{"path":"http://r.bafg.de/reference/getTableAsRecords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a table as a list of ntspRecords — getTableAsRecords","text":"dbComm DbComm connection object tableName Name table database, wildcards permitted searchBlock list coercible json Elasticsearch Search API (Query DSL) fields Fields include response, wildcards permitted, default fields. recordConstructor function construct new records","code":""},{"path":"http://r.bafg.de/reference/getTableAsRecords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a table as a list of ntspRecords — getTableAsRecords","text":"`list` `ntspRecord` objects","code":""},{"path":"http://r.bafg.de/reference/getTableAsTibble.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a table as a tibble — getTableAsTibble","title":"Get a table as a tibble — getTableAsTibble","text":"Works similarly `getTableAsRecords()` reformats `ntspRecords` `tibble`.","code":""},{"path":"http://r.bafg.de/reference/getTableAsTibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a table as a tibble — getTableAsTibble","text":"","code":"getTableAsTibble(dbComm, tableName, searchBlock = list(), fields = \"*\")"},{"path":"http://r.bafg.de/reference/getTableAsTibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a table as a tibble — getTableAsTibble","text":"dbComm DbComm connection object tableName Name table database, wildcards permitted searchBlock list coercible json Elasticsearch Search API (Query DSL) fields Fields include response, wildcards permitted, default fields.","code":""},{"path":"http://r.bafg.de/reference/getTableAsTibble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a table as a tibble — getTableAsTibble","text":"tibble","code":""},{"path":[]},{"path":"http://r.bafg.de/reference/ingest.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest featureRecords into Elasticsearch — ingest","title":"Ingest featureRecords into Elasticsearch — ingest","text":"screening processing output RDS file batch (one large batches). ingested NTSPortal Elasticsearch.","code":""},{"path":"http://r.bafg.de/reference/ingest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest featureRecords into Elasticsearch — ingest","text":"","code":"ingest(path, ingestPipeline = \"ingest-feature\")"},{"path":"http://r.bafg.de/reference/ingest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest featureRecords into Elasticsearch — ingest","text":"path Path single RDS file directory RDS files. ingestPipeline ID ingest pipeline use (default \"ingest-feature\" pipeline)","code":""},{"path":"http://r.bafg.de/reference/ingest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ingest featureRecords into Elasticsearch — ingest","text":"list one top-level entry per batch (RDS file). second level one entry per alias contains character vector index name associated alias.","code":""},{"path":"http://r.bafg.de/reference/ingest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ingest featureRecords into Elasticsearch — ingest","text":"Ingest pipelines Feature documents enriched sample analytical method information using ingest pipeline. Use `ingestPipeline` specify ingest pipeline use (must previously submitted Elasticsearch)","code":""},{"path":"http://r.bafg.de/reference/isTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Does a table exist? — isTable","title":"Does a table exist? — isTable","text":"table exist?","code":""},{"path":"http://r.bafg.de/reference/isTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Does a table exist? — isTable","text":"","code":"isTable(dbComm, tableName)"},{"path":"http://r.bafg.de/reference/isTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Does a table exist? — isTable","text":"dbComm DbComm connection object tableName Name table database, wildcards permitted","code":""},{"path":"http://r.bafg.de/reference/isTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Does a table exist? — isTable","text":"logical, true table exists","code":""},{"path":"http://r.bafg.de/reference/msrawfilesSetVersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Change msrawfiles to a new version — msrawfilesSetVersion","title":"Change msrawfiles to a new version — msrawfilesSetVersion","text":"move new version NTSPortal, `msrawfiles` needs updated new alias names.","code":""},{"path":"http://r.bafg.de/reference/msrawfilesSetVersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change msrawfiles to a new version — msrawfilesSetVersion","text":"","code":"msrawfilesSetVersion(msrawfilesName, version)"},{"path":"http://r.bafg.de/reference/msrawfilesSetVersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change msrawfiles to a new version — msrawfilesSetVersion","text":"msrawfilesName Name `msrawfiles` table version New version number","code":""},{"path":"http://r.bafg.de/reference/msrawfilesSetVersion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change msrawfiles to a new version — msrawfilesSetVersion","text":"","code":"if (FALSE) { # \\dontrun{ msrawfilesSetVersion(\"ntsp25.1_msrawfiles\", \"25.2\") } # }"},{"path":"http://r.bafg.de/reference/ntsportal-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ntsportal: ntsportal - Functions for building and managing the NTSPortal database — ntsportal-package","title":"ntsportal: ntsportal - Functions for building and managing the NTSPortal database — ntsportal-package","text":"package provides functionality building managing NTSPortal database.","code":""},{"path":[]},{"path":"http://r.bafg.de/reference/ntsportal-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ntsportal: ntsportal - Functions for building and managing the NTSPortal database — ntsportal-package","text":"Maintainer: Kevin S. Jewell jewell@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) Authors: Ole Lessmann lessmann@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) contributors: Jonas Skottnik skottnik@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) [contributor] Franziska Prodöhl prodoehl@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) [contributor] Nina Hermes hermes@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) [contributor] Arne Wick wick@bafg.de (Federal Institute Hydrology (BfG) Koblenz, Germany) [reviewer]","code":""},{"path":"http://r.bafg.de/reference/ntsportal.html","id":null,"dir":"Reference","previous_headings":"","what":"ntsportal: A package for non-target data management — ntsportal","title":"ntsportal: A package for non-target data management — ntsportal","text":"ntsportal: package non-target data management","code":""},{"path":"http://r.bafg.de/reference/ping.html","id":null,"dir":"Reference","previous_headings":"","what":"Test the DB-Connection — ping","title":"Test the DB-Connection — ping","text":"Test DB-Connection","code":""},{"path":"http://r.bafg.de/reference/ping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test the DB-Connection — ping","text":"","code":"ping(dbComm)  # S4 method for class 'PythonDbComm' ping(dbComm)"},{"path":"http://r.bafg.de/reference/ping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test the DB-Connection — ping","text":"dbComm DbComm connection object","code":""},{"path":"http://r.bafg.de/reference/ping.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test the DB-Connection — ping","text":"TRUE connection active","code":""},{"path":"http://r.bafg.de/reference/PythonDbComm-class.html","id":null,"dir":"Reference","previous_headings":"","what":"A DbComm interface using the Python back-end — PythonDbComm-class","title":"A DbComm interface using the Python back-end — PythonDbComm-class","text":"object implements DbComm interface","code":""},{"path":"http://r.bafg.de/reference/PythonDbComm-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"A DbComm interface using the Python back-end — PythonDbComm-class","text":"client python elasticsearch client object dsl python elasticsearch.dsl import module rdname PythonDbComm","code":""},{"path":"http://r.bafg.de/reference/PythonDbComm.html","id":null,"dir":"Reference","previous_headings":"","what":"Build Python DB communications interface — PythonDbComm","title":"Build Python DB communications interface — PythonDbComm","text":"generator `PythonDbComm` class.","code":""},{"path":"http://r.bafg.de/reference/PythonDbComm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build Python DB communications interface — PythonDbComm","text":"","code":"PythonDbComm(ring = \"ntsportal\")"},{"path":"http://r.bafg.de/reference/PythonDbComm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build Python DB communications interface — PythonDbComm","text":"ring name keyring NTSPortal credentials stored, see `connectNtsportal()`","code":""},{"path":"http://r.bafg.de/reference/PythonDbComm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build Python DB communications interface — PythonDbComm","text":"PythonDbComm","code":""},{"path":"http://r.bafg.de/reference/removeRedundantPngs.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete redundant PNGs — removeRedundantPngs","title":"Delete redundant PNGs — removeRedundantPngs","text":"Remove PNGs compounds found library","code":""},{"path":"http://r.bafg.de/reference/removeRedundantPngs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete redundant PNGs — removeRedundantPngs","text":"","code":"removeRedundantPngs(databasePath, targetDir)"},{"path":"http://r.bafg.de/reference/removeRedundantPngs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete redundant PNGs — removeRedundantPngs","text":"databasePath Path spectral library (CSL, SQLite format) targetDir Path PNGs saved","code":""},{"path":"http://r.bafg.de/reference/removeValueFromArray.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove a value from an array field — removeValueFromArray","title":"Remove a value from an array field — removeValueFromArray","text":"Remove value array field","code":""},{"path":"http://r.bafg.de/reference/removeValueFromArray.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove a value from an array field — removeValueFromArray","text":"","code":"removeValueFromArray(dbComm, tableName, field, value, searchBlock = list())"},{"path":"http://r.bafg.de/reference/removeValueFromArray.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove a value from an array field — removeValueFromArray","text":"dbComm DbComm connection object tableName Name table database, wildcards permitted field table column (field) name see mappings value value set add searchBlock list coercible json Elasticsearch Search API (Query DSL)","code":""},{"path":[]},{"path":"http://r.bafg.de/reference/resetConnectionCredentials.html","id":null,"dir":"Reference","previous_headings":"","what":"Create connection with new credentials — resetConnectionCredentials","title":"Create connection with new credentials — resetConnectionCredentials","text":"use stored credentials need changed.","code":""},{"path":"http://r.bafg.de/reference/resetConnectionCredentials.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create connection with new credentials — resetConnectionCredentials","text":"","code":"resetConnectionCredentials()"},{"path":"http://r.bafg.de/reference/scanBatchDbas.html","id":null,"dir":"Reference","previous_headings":"","what":"Scan measurement files for known compounds — scanBatchDbas","title":"Scan measurement files for known compounds — scanBatchDbas","text":"spectral library used scan mzXML measurment files compounds using DBAS algorithm. parameters DBAS file locations (measurement files spectral library) stored `msrawfileRecord`s passed `records` argument.","code":""},{"path":"http://r.bafg.de/reference/scanBatchDbas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scan measurement files for known compounds — scanBatchDbas","text":"","code":"scanBatchDbas(records, compsToProcess = NULL, showProgress = FALSE)"},{"path":"http://r.bafg.de/reference/scanBatchDbas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scan measurement files for known compounds — scanBatchDbas","text":"records `list` `msrawfileRecord`s compsToProcess Character vector compounds names include scanning (default compounds spectral library) showProgress Logical, show progress bar? (interacte use, default false)","code":""},{"path":"http://r.bafg.de/reference/scanBatchDbas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scan measurement files for known compounds — scanBatchDbas","text":"`dbasResult` (`list` 7 tables) including `peakList`, `reintegrationResults` etc.","code":""},{"path":"http://r.bafg.de/reference/scanBatchDbas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scan measurement files for known compounds — scanBatchDbas","text":"","code":"if (FALSE) { # \\dontrun{ dbComm <- getDbComm() recs <- getTableAsRecords(   dbComm,    \"ntsp25.2_msrawfiles\",    searchBlock = list(query = list(regexp = list(filename = \"Des_19_.._pos.mzXML\"))),   newMsrawfilesRecord ) recsBlanks <- getTableAsRecords(   dbComm,    \"ntsp25.2_msrawfiles\",    searchBlock = list(query = list(regexp = list(path = \".*mud_pos/BW.*\"))),    newMsrawfilesRecord ) res <- scanBatchDbas(c(recs, recsBlanks), \"Methyltriphenylphosphonium\") } # }"},{"path":"http://r.bafg.de/reference/setCredNonInteractive.html","id":null,"dir":"Reference","previous_headings":"","what":"Set credentials for accessing NTSPortal ElasticSearch — setCredNonInteractive","title":"Set credentials for accessing NTSPortal ElasticSearch — setCredNonInteractive","text":"progammatically setting credentials.","code":""},{"path":"http://r.bafg.de/reference/setCredNonInteractive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set credentials for accessing NTSPortal ElasticSearch — setCredNonInteractive","text":"","code":"setCredNonInteractive(ring = \"ntsportal\", usr = character(), pwd = character())"},{"path":"http://r.bafg.de/reference/setCredNonInteractive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set credentials for accessing NTSPortal ElasticSearch — setCredNonInteractive","text":"ring Keyring name, change default usr username, enter manually non-interactive use pwd password, enter manually non-interactive use","code":""},{"path":"http://r.bafg.de/reference/setValueInField.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the value of a field in a table — setValueInField","title":"Set the value of a field in a table — setValueInField","text":"Used change value field rows (.e. docs) returned `seearchBlock`","code":""},{"path":"http://r.bafg.de/reference/setValueInField.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the value of a field in a table — setValueInField","text":"","code":"setValueInField(dbComm, tableName, field, value, searchBlock = list())"},{"path":"http://r.bafg.de/reference/setValueInField.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the value of a field in a table — setValueInField","text":"dbComm DbComm connection object tableName Name table database, wildcards permitted field table column (field) name see mappings value value set add searchBlock list coercible json Elasticsearch Search API (Query DSL)","code":""},{"path":"http://r.bafg.de/reference/updateEnrichPolicies.html","id":null,"dir":"Reference","previous_headings":"","what":"Update enrich policies in Elasticsearch — updateEnrichPolicies","title":"Update enrich policies in Elasticsearch — updateEnrichPolicies","text":"Refresh (overwrite re-execute) enrich policies stored ntsportal package (inst/enrichPolicies)","code":""},{"path":"http://r.bafg.de/reference/updateEnrichPolicies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update enrich policies in Elasticsearch — updateEnrichPolicies","text":"","code":"updateEnrichPolicies()"},{"path":"http://r.bafg.de/reference/updateEnrichPolicies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update enrich policies in Elasticsearch — updateEnrichPolicies","text":"vector task IDs enrich policy execution tasks","code":""},{"path":"http://r.bafg.de/reference/updateIngestPipelines.html","id":null,"dir":"Reference","previous_headings":"","what":"Update Ingest Pipelines needed for ntsportal on the elasticsearch cluster — updateIngestPipelines","title":"Update Ingest Pipelines needed for ntsportal on the elasticsearch cluster — updateIngestPipelines","text":"Update Ingest Pipelines needed ntsportal elasticsearch cluster","code":""},{"path":"http://r.bafg.de/reference/updateIngestPipelines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update Ingest Pipelines needed for ntsportal on the elasticsearch cluster — updateIngestPipelines","text":"","code":"updateIngestPipelines()"},{"path":"http://r.bafg.de/reference/updateLinearRegressionTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Update the ","title":"Update the ","text":"analysis table shows slope linear regression model compound station DBAS results yearly composite samples SPM (`dbas_upb` table). NTSPortal admin runs function processing update regression results.","code":""},{"path":"http://r.bafg.de/reference/updateLinearRegressionTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update the ","text":"","code":"updateLinearRegressionTable(sourceTableName)"},{"path":"http://r.bafg.de/reference/updateLinearRegressionTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update the ","text":"sourceTableName Table ntsportal analyzed (dbas_upb)","code":""},{"path":"http://r.bafg.de/reference/updateSpectralLibrary.html","id":null,"dir":"Reference","previous_headings":"","what":"Update the CSL spectral library on ntsportal — updateSpectralLibrary","title":"Update the CSL spectral library on ntsportal — updateSpectralLibrary","text":"`spectral_library` table copy CSL use reference Spectral Library dashboard Spectra Chromatograms dashboard. change library used DBAS processing. reprocessing new CSL version, function run update reference table.","code":""},{"path":"http://r.bafg.de/reference/updateSpectralLibrary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update the CSL spectral library on ntsportal — updateSpectralLibrary","text":"","code":"updateSpectralLibrary(rfTableName, specLibTableName)"},{"path":"http://r.bafg.de/reference/updateSpectralLibrary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update the CSL spectral library on ntsportal — updateSpectralLibrary","text":"rfTableName Name msrawfiles table specLibTableName Name new spectral library table (old table overwritten)","code":""},{"path":"http://r.bafg.de/reference/validateRecord.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate that a `*record` is correctly formated — validateRecord","title":"Validate that a `*record` is correctly formated — validateRecord","text":"Checks run conisitency files present disc.","code":""},{"path":"http://r.bafg.de/reference/validateRecord.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate that a `*record` is correctly formated — validateRecord","text":"","code":"validateRecord(record)  # S3 method for class 'msrawfilesRecord' validateRecord(record)  # S3 method for class 'featureRecord' validateRecord(record)"},{"path":[]},{"path":"http://r.bafg.de/news/index.html","id":"major-changes-25-2","dir":"Changelog","previous_headings":"","what":"Major changes","title":"ntsportal 25.2","text":"dbaScreening*() now save records RDS files rather compressed JSON files (necessary due licence compatibility issues). RDS files ingest must contain ntsportal-featureRecord name. Added new field dbas tables: score_ms2_match gives ms² match score (0-1000). used “Spectra Annotated Features” dashboard show ) number MS² matches dataset b) distribution MS² matching scores (histogram) Sample metadata added dbas documents ingest (enrich policy ingest pipeline, similar join). reduce redundancy output RDS files. See inst/enrichPolicies inst/ingestPipelines. user required update enrich policies prior ingest updateEnrichPolicies() Fixed bug whereby peak areas overwritten peak intensities Updated use CSL v25.5 ntsworkflow 0.2.9","code":""},{"path":"http://r.bafg.de/news/index.html","id":"minor-changes-25-2","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"ntsportal 25.2","text":"Added batch consistency checks checkMsrawfiles() Added functions manipulating array type fields documents","code":""},{"path":[]},{"path":"http://r.bafg.de/news/index.html","id":"major-changes-25-1","dir":"Changelog","previous_headings":"","what":"Major changes","title":"ntsportal 25.1","text":"Temporary removal processing indexing unknown features (ntsp_nts indices) stable release ntsp_dbas indices achieved. Introduced unified versioning system back-end, front-end database content based ntsp25.1 form. Index naming now takes form ntsp25.<X>_dbas_<code>. Likewise front end (Kibana space ID: ntsportal-2025-1). Moved DB communication S4-based interface class implemented methods using official python elasticsearch client via reticulate. Agglomeration documentation wikis pkgdown site. Refactoring much code large expansion tests.","code":""}]
